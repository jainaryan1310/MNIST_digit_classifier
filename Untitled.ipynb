{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e77bae2-2e9b-4754-80bf-d2f49c1dec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2841920-b82c-4b19-899c-bbd20f730017",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f56fa7-aa65-453a-8ae5-09897a45fd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eefeb3-4fae-45f9-bc88-2195b93a73cf",
   "metadata": {},
   "source": [
    "USING A PRETRAINED VGG MODEL TO DEVELOP END TO END PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4294b625-1e03-40b9-b3fa-f14f1134e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), T.Normalize((0.485, ), (0.229, )), T.Lambda(lambda x : x.repeat(3, 1, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af93a1-2120-46d8-be80-422a53e9d7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=pretrain_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249a834-b59a-43fe-8b68-c620b1d6a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda9f8a-3ab8-448e-92f8-cc6358b4f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de5b81-6787-4d2c-94ff-0bb4bf5be548",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_testset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "  for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    test_loss += loss(output, target)\n",
    "    pred = output.data.max(1, keepdim = True)[1]\n",
    "    correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(mnist_testset)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b1a20-ddaf-4ee9-83c4-daf4df149514",
   "metadata": {},
   "source": [
    "TRAINING A MODEL FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdc4a0-b024-454c-ba4f-4a07685dd2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.model = nn.Sequential(# (N, 1, 224, 224)\n",
    "                                   nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                   # (N, 64, 224, 224)\n",
    "                                   nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(128, 128, kernel_size=2, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                   # (N, 128, 224, 224)\n",
    "                                   nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                   # (N, 256, 224, 224)\n",
    "                                   nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                   # (N, 512, 224, 224)\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                   # (N, 512, 224, 224)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(                  \n",
    "           nn.Linear(in_features=512*3*3, out_features=4096),\n",
    "           nn.ReLU(inplace=True),\n",
    "           nn.Dropout(p=0.5, inplace=False),\n",
    "           nn.Linear(in_features=4096, out_features=4096),\n",
    "           nn.ReLU(inplace=True),\n",
    "           nn.Dropout(p=0.5, inplace=False),\n",
    "           nn.Linear(in_features=4096, out_features=1000),\n",
    "           nn.ReLU(inplace=True),\n",
    "             )\n",
    "        \n",
    "    def forward(self, feat):\n",
    "        #print(feat.shape)\n",
    "        features = self.model(feat)\n",
    "        #print(features.shape)\n",
    "        features = features.view(features.shape[0],-1)\n",
    "        #print(features.shape)\n",
    "        features = self.classifier(features)\n",
    "        #print(features.shape)\n",
    "        return F.log_softmax(features)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1092cc5-f77f-4ebd-b53f-3bf8b70bbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "learning_rate = 0.01\n",
    "BATCH_SIZE = 32\n",
    "momentum = 0.5\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6345f655-d9be-4a2b-ba62-c0871450d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7f61b0-db92-45d5-9ed1-cb903f90b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(vgg16.parameters(), lr = learning_rate, momentum = momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d285a01e-944b-4839-a0e1-0dcfe391e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), T.Normalize((0.485, ), (0.229, )), T.Lambda(lambda x : x.repeat(3, 1, 1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade78fb3-e64a-4211-9722-58ca8e8bc4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b75e8e-96a5-48ab-b143-40ba389c3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e460668-ff39-4c63-b54f-76254b68fcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/software/anaconda3/envs/ML/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-19kunu9c/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.21684777736663818, Accuracy: 0/10000 (0.0%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0.0%)]\tLoss: 6.942816257476807\n",
      "Train Epoch: 1 [320/60000 (0.5333333333333333%)]\tLoss: 6.793944358825684\n",
      "Train Epoch: 1 [640/60000 (1.0666666666666667%)]\tLoss: 6.136723518371582\n",
      "Train Epoch: 1 [960/60000 (1.6%)]\tLoss: 6.607276916503906\n",
      "Train Epoch: 1 [1280/60000 (2.1333333333333333%)]\tLoss: 6.638305187225342\n",
      "Train Epoch: 1 [1600/60000 (2.6666666666666665%)]\tLoss: 6.081721782684326\n",
      "Train Epoch: 1 [1920/60000 (3.2%)]\tLoss: 3.9431657791137695\n",
      "Train Epoch: 1 [2240/60000 (3.7333333333333334%)]\tLoss: 2.953589677810669\n",
      "Train Epoch: 1 [2560/60000 (4.266666666666667%)]\tLoss: 2.3496851921081543\n",
      "Train Epoch: 1 [2880/60000 (4.8%)]\tLoss: 2.4564781188964844\n",
      "Train Epoch: 1 [3200/60000 (5.333333333333333%)]\tLoss: 2.4021973609924316\n",
      "Train Epoch: 1 [3520/60000 (5.866666666666666%)]\tLoss: 2.5385689735412598\n",
      "Train Epoch: 1 [3840/60000 (6.4%)]\tLoss: 2.323815107345581\n",
      "Train Epoch: 1 [4160/60000 (6.933333333333334%)]\tLoss: 2.183745861053467\n",
      "Train Epoch: 1 [4480/60000 (7.466666666666667%)]\tLoss: 1.7715449333190918\n",
      "Train Epoch: 1 [4800/60000 (8.0%)]\tLoss: 1.5349737405776978\n",
      "Train Epoch: 1 [5120/60000 (8.533333333333333%)]\tLoss: 2.2447574138641357\n",
      "Train Epoch: 1 [5440/60000 (9.066666666666666%)]\tLoss: 0.7725577354431152\n",
      "Train Epoch: 1 [5760/60000 (9.6%)]\tLoss: 0.7626092433929443\n",
      "Train Epoch: 1 [6080/60000 (10.133333333333333%)]\tLoss: 1.1785011291503906\n",
      "Train Epoch: 1 [6400/60000 (10.666666666666666%)]\tLoss: 0.5543882846832275\n",
      "Train Epoch: 1 [6720/60000 (11.2%)]\tLoss: 0.4766348600387573\n",
      "Train Epoch: 1 [7040/60000 (11.733333333333333%)]\tLoss: 0.40421217679977417\n",
      "Train Epoch: 1 [7360/60000 (12.266666666666667%)]\tLoss: 0.6273452639579773\n",
      "Train Epoch: 1 [7680/60000 (12.8%)]\tLoss: 0.09099417179822922\n",
      "Train Epoch: 1 [8000/60000 (13.333333333333334%)]\tLoss: 0.3398436903953552\n",
      "Train Epoch: 1 [8320/60000 (13.866666666666667%)]\tLoss: 0.38536909222602844\n",
      "Train Epoch: 1 [8640/60000 (14.4%)]\tLoss: 0.3091875910758972\n",
      "Train Epoch: 1 [8960/60000 (14.933333333333334%)]\tLoss: 0.3436989486217499\n",
      "Train Epoch: 1 [9280/60000 (15.466666666666667%)]\tLoss: 0.2870662808418274\n",
      "Train Epoch: 1 [9600/60000 (16.0%)]\tLoss: 0.13450388610363007\n",
      "Train Epoch: 1 [9920/60000 (16.533333333333335%)]\tLoss: 0.1618024855852127\n",
      "Train Epoch: 1 [10240/60000 (17.066666666666666%)]\tLoss: 0.3279550075531006\n",
      "Train Epoch: 1 [10560/60000 (17.6%)]\tLoss: 0.28872695565223694\n",
      "Train Epoch: 1 [10880/60000 (18.133333333333333%)]\tLoss: 0.26048141717910767\n",
      "Train Epoch: 1 [11200/60000 (18.666666666666668%)]\tLoss: 0.19800569117069244\n",
      "Train Epoch: 1 [11520/60000 (19.2%)]\tLoss: 0.344888836145401\n",
      "Train Epoch: 1 [11840/60000 (19.733333333333334%)]\tLoss: 0.268669456243515\n",
      "Train Epoch: 1 [12160/60000 (20.266666666666666%)]\tLoss: 0.18822766840457916\n",
      "Train Epoch: 1 [12480/60000 (20.8%)]\tLoss: 0.2765137553215027\n",
      "Train Epoch: 1 [12800/60000 (21.333333333333332%)]\tLoss: 0.07515762746334076\n",
      "Train Epoch: 1 [13120/60000 (21.866666666666667%)]\tLoss: 0.3533967137336731\n",
      "Train Epoch: 1 [13440/60000 (22.4%)]\tLoss: 0.07970201224088669\n",
      "Train Epoch: 1 [13760/60000 (22.933333333333334%)]\tLoss: 0.15087392926216125\n",
      "Train Epoch: 1 [14080/60000 (23.466666666666665%)]\tLoss: 0.16726268827915192\n",
      "Train Epoch: 1 [14400/60000 (24.0%)]\tLoss: 0.06589456647634506\n",
      "Train Epoch: 1 [14720/60000 (24.533333333333335%)]\tLoss: 0.20595596730709076\n",
      "Train Epoch: 1 [15040/60000 (25.066666666666666%)]\tLoss: 0.028139585629105568\n",
      "Train Epoch: 1 [15360/60000 (25.6%)]\tLoss: 0.2117738127708435\n",
      "Train Epoch: 1 [15680/60000 (26.133333333333333%)]\tLoss: 0.06905025243759155\n",
      "Train Epoch: 1 [16000/60000 (26.666666666666668%)]\tLoss: 0.15573032200336456\n",
      "Train Epoch: 1 [16320/60000 (27.2%)]\tLoss: 0.10710280388593674\n",
      "Train Epoch: 1 [16640/60000 (27.733333333333334%)]\tLoss: 0.08519618213176727\n",
      "Train Epoch: 1 [16960/60000 (28.266666666666666%)]\tLoss: 0.18701232969760895\n",
      "Train Epoch: 1 [17280/60000 (28.8%)]\tLoss: 0.09185001999139786\n",
      "Train Epoch: 1 [17600/60000 (29.333333333333332%)]\tLoss: 0.18233226239681244\n",
      "Train Epoch: 1 [17920/60000 (29.866666666666667%)]\tLoss: 0.04359355941414833\n",
      "Train Epoch: 1 [18240/60000 (30.4%)]\tLoss: 0.0963360145688057\n",
      "Train Epoch: 1 [18560/60000 (30.933333333333334%)]\tLoss: 0.05428708344697952\n",
      "Train Epoch: 1 [18880/60000 (31.466666666666665%)]\tLoss: 0.027584897354245186\n",
      "Train Epoch: 1 [19200/60000 (32.0%)]\tLoss: 0.09101870656013489\n",
      "Train Epoch: 1 [19520/60000 (32.53333333333333%)]\tLoss: 0.157246932387352\n",
      "Train Epoch: 1 [19840/60000 (33.06666666666667%)]\tLoss: 0.3000831604003906\n",
      "Train Epoch: 1 [20160/60000 (33.6%)]\tLoss: 0.2421053946018219\n",
      "Train Epoch: 1 [20480/60000 (34.13333333333333%)]\tLoss: 0.015737384557724\n",
      "Train Epoch: 1 [20800/60000 (34.666666666666664%)]\tLoss: 0.13159656524658203\n",
      "Train Epoch: 1 [21120/60000 (35.2%)]\tLoss: 0.203087717294693\n",
      "Train Epoch: 1 [21440/60000 (35.733333333333334%)]\tLoss: 0.27052175998687744\n",
      "Train Epoch: 1 [21760/60000 (36.266666666666666%)]\tLoss: 0.014809206128120422\n",
      "Train Epoch: 1 [22080/60000 (36.8%)]\tLoss: 0.10316722095012665\n",
      "Train Epoch: 1 [22400/60000 (37.333333333333336%)]\tLoss: 0.10324124246835709\n",
      "Train Epoch: 1 [22720/60000 (37.86666666666667%)]\tLoss: 0.1567980796098709\n",
      "Train Epoch: 1 [23040/60000 (38.4%)]\tLoss: 0.010886109434068203\n",
      "Train Epoch: 1 [23360/60000 (38.93333333333333%)]\tLoss: 0.02906036749482155\n",
      "Train Epoch: 1 [23680/60000 (39.46666666666667%)]\tLoss: 0.18080782890319824\n",
      "Train Epoch: 1 [24000/60000 (40.0%)]\tLoss: 0.059609342366456985\n",
      "Train Epoch: 1 [24320/60000 (40.53333333333333%)]\tLoss: 0.05986541882157326\n",
      "Train Epoch: 1 [24640/60000 (41.06666666666667%)]\tLoss: 0.09782923758029938\n",
      "Train Epoch: 1 [24960/60000 (41.6%)]\tLoss: 0.05160525068640709\n",
      "Train Epoch: 1 [25280/60000 (42.13333333333333%)]\tLoss: 0.507143497467041\n",
      "Train Epoch: 1 [25600/60000 (42.666666666666664%)]\tLoss: 0.040300577878952026\n",
      "Train Epoch: 1 [25920/60000 (43.2%)]\tLoss: 0.0881488248705864\n",
      "Train Epoch: 1 [26240/60000 (43.733333333333334%)]\tLoss: 0.05189352110028267\n",
      "Train Epoch: 1 [26560/60000 (44.266666666666666%)]\tLoss: 0.42965033650398254\n",
      "Train Epoch: 1 [26880/60000 (44.8%)]\tLoss: 0.35832494497299194\n",
      "Train Epoch: 1 [27200/60000 (45.333333333333336%)]\tLoss: 0.04385760799050331\n",
      "Train Epoch: 1 [27520/60000 (45.86666666666667%)]\tLoss: 0.3988521993160248\n",
      "Train Epoch: 1 [27840/60000 (46.4%)]\tLoss: 0.05600164458155632\n",
      "Train Epoch: 1 [28160/60000 (46.93333333333333%)]\tLoss: 0.16801807284355164\n",
      "Train Epoch: 1 [28480/60000 (47.46666666666667%)]\tLoss: 0.11176040023565292\n",
      "Train Epoch: 1 [28800/60000 (48.0%)]\tLoss: 0.12381578981876373\n",
      "Train Epoch: 1 [29120/60000 (48.53333333333333%)]\tLoss: 0.1430213302373886\n",
      "Train Epoch: 1 [29440/60000 (49.06666666666667%)]\tLoss: 0.16106508672237396\n",
      "Train Epoch: 1 [29760/60000 (49.6%)]\tLoss: 0.026446552947163582\n",
      "Train Epoch: 1 [30080/60000 (50.13333333333333%)]\tLoss: 0.08480514585971832\n",
      "Train Epoch: 1 [30400/60000 (50.666666666666664%)]\tLoss: 0.00987282209098339\n",
      "Train Epoch: 1 [30720/60000 (51.2%)]\tLoss: 0.250434935092926\n",
      "Train Epoch: 1 [31040/60000 (51.733333333333334%)]\tLoss: 0.04205099120736122\n",
      "Train Epoch: 1 [31360/60000 (52.266666666666666%)]\tLoss: 0.12707334756851196\n",
      "Train Epoch: 1 [31680/60000 (52.8%)]\tLoss: 0.14303746819496155\n",
      "Train Epoch: 1 [32000/60000 (53.333333333333336%)]\tLoss: 0.11266162246465683\n",
      "Train Epoch: 1 [32320/60000 (53.86666666666667%)]\tLoss: 0.5039612650871277\n",
      "Train Epoch: 1 [32640/60000 (54.4%)]\tLoss: 0.11302029341459274\n",
      "Train Epoch: 1 [32960/60000 (54.93333333333333%)]\tLoss: 0.006049862131476402\n",
      "Train Epoch: 1 [33280/60000 (55.46666666666667%)]\tLoss: 0.23188795149326324\n",
      "Train Epoch: 1 [33600/60000 (56.0%)]\tLoss: 0.03907061368227005\n",
      "Train Epoch: 1 [33920/60000 (56.53333333333333%)]\tLoss: 0.030731577426195145\n",
      "Train Epoch: 1 [34240/60000 (57.06666666666667%)]\tLoss: 0.007283687125891447\n",
      "Train Epoch: 1 [34560/60000 (57.6%)]\tLoss: 0.038308531045913696\n",
      "Train Epoch: 1 [34880/60000 (58.13333333333333%)]\tLoss: 0.08268163353204727\n",
      "Train Epoch: 1 [35200/60000 (58.666666666666664%)]\tLoss: 0.07618624716997147\n",
      "Train Epoch: 1 [35520/60000 (59.2%)]\tLoss: 0.08062184602022171\n",
      "Train Epoch: 1 [35840/60000 (59.733333333333334%)]\tLoss: 0.22865062952041626\n",
      "Train Epoch: 1 [36160/60000 (60.266666666666666%)]\tLoss: 0.01790292002260685\n",
      "Train Epoch: 1 [36480/60000 (60.8%)]\tLoss: 0.07673365622758865\n",
      "Train Epoch: 1 [36800/60000 (61.333333333333336%)]\tLoss: 0.0680357962846756\n",
      "Train Epoch: 1 [37120/60000 (61.86666666666667%)]\tLoss: 0.02753450535237789\n",
      "Train Epoch: 1 [37440/60000 (62.4%)]\tLoss: 0.24085809290409088\n",
      "Train Epoch: 1 [37760/60000 (62.93333333333333%)]\tLoss: 0.017226194962859154\n",
      "Train Epoch: 1 [38080/60000 (63.46666666666667%)]\tLoss: 0.022883879020810127\n",
      "Train Epoch: 1 [38400/60000 (64.0%)]\tLoss: 0.15608413517475128\n",
      "Train Epoch: 1 [38720/60000 (64.53333333333333%)]\tLoss: 0.07236789166927338\n",
      "Train Epoch: 1 [39040/60000 (65.06666666666666%)]\tLoss: 0.0051316432654857635\n",
      "Train Epoch: 1 [39360/60000 (65.6%)]\tLoss: 0.3979681730270386\n",
      "Train Epoch: 1 [39680/60000 (66.13333333333334%)]\tLoss: 0.0945034772157669\n",
      "Train Epoch: 1 [40000/60000 (66.66666666666667%)]\tLoss: 0.13258832693099976\n",
      "Train Epoch: 1 [40320/60000 (67.2%)]\tLoss: 0.019629815593361855\n",
      "Train Epoch: 1 [40640/60000 (67.73333333333333%)]\tLoss: 0.18617621064186096\n",
      "Train Epoch: 1 [40960/60000 (68.26666666666667%)]\tLoss: 0.21261529624462128\n",
      "Train Epoch: 1 [41280/60000 (68.8%)]\tLoss: 0.24577632546424866\n",
      "Train Epoch: 1 [41600/60000 (69.33333333333333%)]\tLoss: 0.14107289910316467\n",
      "Train Epoch: 1 [41920/60000 (69.86666666666666%)]\tLoss: 0.04206860810518265\n",
      "Train Epoch: 1 [42240/60000 (70.4%)]\tLoss: 0.03585111349821091\n",
      "Train Epoch: 1 [42560/60000 (70.93333333333334%)]\tLoss: 0.21281647682189941\n",
      "Train Epoch: 1 [42880/60000 (71.46666666666667%)]\tLoss: 0.10866479575634003\n",
      "Train Epoch: 1 [43200/60000 (72.0%)]\tLoss: 0.19850067794322968\n",
      "Train Epoch: 1 [43520/60000 (72.53333333333333%)]\tLoss: 0.16938914358615875\n",
      "Train Epoch: 1 [43840/60000 (73.06666666666666%)]\tLoss: 0.055071871727705\n",
      "Train Epoch: 1 [44160/60000 (73.6%)]\tLoss: 0.035221390426158905\n",
      "Train Epoch: 1 [44480/60000 (74.13333333333334%)]\tLoss: 0.08231894671916962\n",
      "Train Epoch: 1 [44800/60000 (74.66666666666667%)]\tLoss: 0.005720937624573708\n",
      "Train Epoch: 1 [45120/60000 (75.2%)]\tLoss: 0.2883509695529938\n",
      "Train Epoch: 1 [45440/60000 (75.73333333333333%)]\tLoss: 0.04029770568013191\n",
      "Train Epoch: 1 [45760/60000 (76.26666666666667%)]\tLoss: 0.19140475988388062\n",
      "Train Epoch: 1 [46080/60000 (76.8%)]\tLoss: 0.319263756275177\n",
      "Train Epoch: 1 [46400/60000 (77.33333333333333%)]\tLoss: 0.16168493032455444\n",
      "Train Epoch: 1 [46720/60000 (77.86666666666666%)]\tLoss: 0.17771992087364197\n",
      "Train Epoch: 1 [47040/60000 (78.4%)]\tLoss: 0.01001477800309658\n",
      "Train Epoch: 1 [47360/60000 (78.93333333333334%)]\tLoss: 0.18570879101753235\n",
      "Train Epoch: 1 [47680/60000 (79.46666666666667%)]\tLoss: 0.19881165027618408\n",
      "Train Epoch: 1 [48000/60000 (80.0%)]\tLoss: 0.01052266638725996\n",
      "Train Epoch: 1 [48320/60000 (80.53333333333333%)]\tLoss: 0.0318790040910244\n",
      "Train Epoch: 1 [48640/60000 (81.06666666666666%)]\tLoss: 0.07956476509571075\n",
      "Train Epoch: 1 [48960/60000 (81.6%)]\tLoss: 0.3038100302219391\n",
      "Train Epoch: 1 [49280/60000 (82.13333333333334%)]\tLoss: 0.012890095822513103\n",
      "Train Epoch: 1 [49600/60000 (82.66666666666667%)]\tLoss: 0.03082321770489216\n",
      "Train Epoch: 1 [49920/60000 (83.2%)]\tLoss: 0.02839856594800949\n",
      "Train Epoch: 1 [50240/60000 (83.73333333333333%)]\tLoss: 0.07714847475290298\n",
      "Train Epoch: 1 [50560/60000 (84.26666666666667%)]\tLoss: 0.06867826730012894\n",
      "Train Epoch: 1 [50880/60000 (84.8%)]\tLoss: 0.1545175015926361\n",
      "Train Epoch: 1 [51200/60000 (85.33333333333333%)]\tLoss: 0.017376568168401718\n",
      "Train Epoch: 1 [51520/60000 (85.86666666666666%)]\tLoss: 0.3302583396434784\n",
      "Train Epoch: 1 [51840/60000 (86.4%)]\tLoss: 0.12478800863027573\n",
      "Train Epoch: 1 [52160/60000 (86.93333333333334%)]\tLoss: 0.0925779715180397\n",
      "Train Epoch: 1 [52480/60000 (87.46666666666667%)]\tLoss: 0.01712009683251381\n",
      "Train Epoch: 1 [52800/60000 (88.0%)]\tLoss: 0.10454533249139786\n",
      "Train Epoch: 1 [53120/60000 (88.53333333333333%)]\tLoss: 0.07416875660419464\n",
      "Train Epoch: 1 [53440/60000 (89.06666666666666%)]\tLoss: 0.12061583995819092\n",
      "Train Epoch: 1 [53760/60000 (89.6%)]\tLoss: 0.024095293134450912\n",
      "Train Epoch: 1 [54080/60000 (90.13333333333334%)]\tLoss: 0.055704329162836075\n",
      "Train Epoch: 1 [54400/60000 (90.66666666666667%)]\tLoss: 0.00028588788700290024\n",
      "Train Epoch: 1 [54720/60000 (91.2%)]\tLoss: 0.020103594288229942\n",
      "Train Epoch: 1 [55040/60000 (91.73333333333333%)]\tLoss: 0.029112456366419792\n",
      "Train Epoch: 1 [55360/60000 (92.26666666666667%)]\tLoss: 0.014157627709209919\n",
      "Train Epoch: 1 [55680/60000 (92.8%)]\tLoss: 0.006990900728851557\n",
      "Train Epoch: 1 [56000/60000 (93.33333333333333%)]\tLoss: 0.0673704743385315\n",
      "Train Epoch: 1 [56320/60000 (93.86666666666666%)]\tLoss: 0.0068860589526593685\n",
      "Train Epoch: 1 [56640/60000 (94.4%)]\tLoss: 0.019991213455796242\n",
      "Train Epoch: 1 [56960/60000 (94.93333333333334%)]\tLoss: 0.06492453813552856\n",
      "Train Epoch: 1 [57280/60000 (95.46666666666667%)]\tLoss: 0.13674524426460266\n",
      "Train Epoch: 1 [57600/60000 (96.0%)]\tLoss: 0.020297618582844734\n",
      "Train Epoch: 1 [57920/60000 (96.53333333333333%)]\tLoss: 0.006361469626426697\n",
      "Train Epoch: 1 [58240/60000 (97.06666666666666%)]\tLoss: 0.004386290442198515\n",
      "Train Epoch: 1 [58560/60000 (97.6%)]\tLoss: 0.01595487631857395\n",
      "Train Epoch: 1 [58880/60000 (98.13333333333334%)]\tLoss: 0.001386390533298254\n",
      "Train Epoch: 1 [59200/60000 (98.66666666666667%)]\tLoss: 0.0016036502784118056\n",
      "Train Epoch: 1 [59520/60000 (99.2%)]\tLoss: 0.0003188523114658892\n",
      "Train Epoch: 1 [59840/60000 (99.73333333333333%)]\tLoss: 0.011760860681533813\n",
      "\n",
      "Test set: Avg. loss: 0.0019454661523923278, Accuracy: 9836/10000 (98.36000061035156%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0.0%)]\tLoss: 0.059463731944561005\n",
      "Train Epoch: 2 [320/60000 (0.5333333333333333%)]\tLoss: 0.008609773591160774\n",
      "Train Epoch: 2 [640/60000 (1.0666666666666667%)]\tLoss: 0.007839523255825043\n",
      "Train Epoch: 2 [960/60000 (1.6%)]\tLoss: 0.10012835264205933\n",
      "Train Epoch: 2 [1280/60000 (2.1333333333333333%)]\tLoss: 0.0129330949857831\n",
      "Train Epoch: 2 [1600/60000 (2.6666666666666665%)]\tLoss: 0.23711887001991272\n",
      "Train Epoch: 2 [1920/60000 (3.2%)]\tLoss: 0.08250199258327484\n",
      "Train Epoch: 2 [2240/60000 (3.7333333333333334%)]\tLoss: 0.0849236249923706\n",
      "Train Epoch: 2 [2560/60000 (4.266666666666667%)]\tLoss: 0.014683043584227562\n",
      "Train Epoch: 2 [2880/60000 (4.8%)]\tLoss: 0.020342616364359856\n",
      "Train Epoch: 2 [3200/60000 (5.333333333333333%)]\tLoss: 0.07998474687337875\n",
      "Train Epoch: 2 [3520/60000 (5.866666666666666%)]\tLoss: 0.022148167714476585\n",
      "Train Epoch: 2 [3840/60000 (6.4%)]\tLoss: 0.004547834862023592\n",
      "Train Epoch: 2 [4160/60000 (6.933333333333334%)]\tLoss: 0.0479295551776886\n",
      "Train Epoch: 2 [4480/60000 (7.466666666666667%)]\tLoss: 0.11483457684516907\n",
      "Train Epoch: 2 [4800/60000 (8.0%)]\tLoss: 0.04994027316570282\n",
      "Train Epoch: 2 [5120/60000 (8.533333333333333%)]\tLoss: 0.1277802437543869\n",
      "Train Epoch: 2 [5440/60000 (9.066666666666666%)]\tLoss: 0.05686298757791519\n",
      "Train Epoch: 2 [5760/60000 (9.6%)]\tLoss: 0.1384046971797943\n",
      "Train Epoch: 2 [6080/60000 (10.133333333333333%)]\tLoss: 0.03368639945983887\n",
      "Train Epoch: 2 [6400/60000 (10.666666666666666%)]\tLoss: 0.07391434162855148\n",
      "Train Epoch: 2 [6720/60000 (11.2%)]\tLoss: 0.012204529717564583\n",
      "Train Epoch: 2 [7040/60000 (11.733333333333333%)]\tLoss: 0.025400474667549133\n",
      "Train Epoch: 2 [7360/60000 (12.266666666666667%)]\tLoss: 0.07056212425231934\n",
      "Train Epoch: 2 [7680/60000 (12.8%)]\tLoss: 0.009313199669122696\n",
      "Train Epoch: 2 [8000/60000 (13.333333333333334%)]\tLoss: 0.07083157449960709\n",
      "Train Epoch: 2 [8320/60000 (13.866666666666667%)]\tLoss: 0.0529421865940094\n",
      "Train Epoch: 2 [8640/60000 (14.4%)]\tLoss: 0.05982740595936775\n",
      "Train Epoch: 2 [8960/60000 (14.933333333333334%)]\tLoss: 0.19230367243289948\n",
      "Train Epoch: 2 [9280/60000 (15.466666666666667%)]\tLoss: 0.1591707170009613\n",
      "Train Epoch: 2 [9600/60000 (16.0%)]\tLoss: 0.029576579108834267\n",
      "Train Epoch: 2 [9920/60000 (16.533333333333335%)]\tLoss: 0.0237323809415102\n",
      "Train Epoch: 2 [10240/60000 (17.066666666666666%)]\tLoss: 0.06903286278247833\n",
      "Train Epoch: 2 [10560/60000 (17.6%)]\tLoss: 0.0007582980906590819\n",
      "Train Epoch: 2 [10880/60000 (18.133333333333333%)]\tLoss: 0.018348412588238716\n",
      "Train Epoch: 2 [11200/60000 (18.666666666666668%)]\tLoss: 0.1492629200220108\n",
      "Train Epoch: 2 [11520/60000 (19.2%)]\tLoss: 0.03693396598100662\n",
      "Train Epoch: 2 [11840/60000 (19.733333333333334%)]\tLoss: 0.018350770696997643\n",
      "Train Epoch: 2 [12160/60000 (20.266666666666666%)]\tLoss: 0.055658403784036636\n",
      "Train Epoch: 2 [12480/60000 (20.8%)]\tLoss: 0.002230084966868162\n",
      "Train Epoch: 2 [12800/60000 (21.333333333333332%)]\tLoss: 0.10167435556650162\n",
      "Train Epoch: 2 [13120/60000 (21.866666666666667%)]\tLoss: 0.05644658952951431\n",
      "Train Epoch: 2 [13440/60000 (22.4%)]\tLoss: 0.004432620946317911\n",
      "Train Epoch: 2 [13760/60000 (22.933333333333334%)]\tLoss: 0.0017293744022026658\n",
      "Train Epoch: 2 [14080/60000 (23.466666666666665%)]\tLoss: 0.0030472949147224426\n",
      "Train Epoch: 2 [14400/60000 (24.0%)]\tLoss: 0.010371988639235497\n",
      "Train Epoch: 2 [14720/60000 (24.533333333333335%)]\tLoss: 0.06331411004066467\n",
      "Train Epoch: 2 [15040/60000 (25.066666666666666%)]\tLoss: 0.03306609019637108\n",
      "Train Epoch: 2 [15360/60000 (25.6%)]\tLoss: 0.05946213752031326\n",
      "Train Epoch: 2 [15680/60000 (26.133333333333333%)]\tLoss: 0.001947192708030343\n",
      "Train Epoch: 2 [16000/60000 (26.666666666666668%)]\tLoss: 0.02667144313454628\n",
      "Train Epoch: 2 [16320/60000 (27.2%)]\tLoss: 0.0041692666709423065\n",
      "Train Epoch: 2 [16640/60000 (27.733333333333334%)]\tLoss: 0.18244823813438416\n",
      "Train Epoch: 2 [16960/60000 (28.266666666666666%)]\tLoss: 0.09303058683872223\n",
      "Train Epoch: 2 [17280/60000 (28.8%)]\tLoss: 0.031159471720457077\n",
      "Train Epoch: 2 [17600/60000 (29.333333333333332%)]\tLoss: 0.04980458319187164\n",
      "Train Epoch: 2 [17920/60000 (29.866666666666667%)]\tLoss: 0.061748944222927094\n",
      "Train Epoch: 2 [18240/60000 (30.4%)]\tLoss: 0.05039509758353233\n",
      "Train Epoch: 2 [18560/60000 (30.933333333333334%)]\tLoss: 0.03969031944870949\n",
      "Train Epoch: 2 [18880/60000 (31.466666666666665%)]\tLoss: 0.0014537835959345102\n",
      "Train Epoch: 2 [19200/60000 (32.0%)]\tLoss: 0.0732170045375824\n",
      "Train Epoch: 2 [19520/60000 (32.53333333333333%)]\tLoss: 0.01591537334024906\n",
      "Train Epoch: 2 [19840/60000 (33.06666666666667%)]\tLoss: 0.004486482590436935\n",
      "Train Epoch: 2 [20160/60000 (33.6%)]\tLoss: 0.19716326892375946\n",
      "Train Epoch: 2 [20480/60000 (34.13333333333333%)]\tLoss: 0.0015827332390472293\n",
      "Train Epoch: 2 [20800/60000 (34.666666666666664%)]\tLoss: 0.010152730159461498\n",
      "Train Epoch: 2 [21120/60000 (35.2%)]\tLoss: 0.04522373154759407\n",
      "Train Epoch: 2 [21440/60000 (35.733333333333334%)]\tLoss: 0.0074892807751894\n",
      "Train Epoch: 2 [21760/60000 (36.266666666666666%)]\tLoss: 0.020620176568627357\n",
      "Train Epoch: 2 [22080/60000 (36.8%)]\tLoss: 0.019320810213685036\n",
      "Train Epoch: 2 [22400/60000 (37.333333333333336%)]\tLoss: 0.03665069490671158\n",
      "Train Epoch: 2 [22720/60000 (37.86666666666667%)]\tLoss: 0.003316939342767\n",
      "Train Epoch: 2 [23040/60000 (38.4%)]\tLoss: 0.0012913988903164864\n",
      "Train Epoch: 2 [23360/60000 (38.93333333333333%)]\tLoss: 0.008790189400315285\n",
      "Train Epoch: 2 [23680/60000 (39.46666666666667%)]\tLoss: 0.05009599030017853\n",
      "Train Epoch: 2 [24000/60000 (40.0%)]\tLoss: 0.03392554074525833\n",
      "Train Epoch: 2 [24320/60000 (40.53333333333333%)]\tLoss: 0.00024850244517438114\n",
      "Train Epoch: 2 [24640/60000 (41.06666666666667%)]\tLoss: 0.07554929703474045\n",
      "Train Epoch: 2 [24960/60000 (41.6%)]\tLoss: 0.006556713487952948\n",
      "Train Epoch: 2 [25280/60000 (42.13333333333333%)]\tLoss: 0.16129054129123688\n",
      "Train Epoch: 2 [25600/60000 (42.666666666666664%)]\tLoss: 0.08730721473693848\n",
      "Train Epoch: 2 [25920/60000 (43.2%)]\tLoss: 0.03271669149398804\n",
      "Train Epoch: 2 [26240/60000 (43.733333333333334%)]\tLoss: 0.002898110542446375\n",
      "Train Epoch: 2 [26560/60000 (44.266666666666666%)]\tLoss: 0.2735406458377838\n",
      "Train Epoch: 2 [26880/60000 (44.8%)]\tLoss: 0.1443067193031311\n",
      "Train Epoch: 2 [27200/60000 (45.333333333333336%)]\tLoss: 0.004673279821872711\n",
      "Train Epoch: 2 [27520/60000 (45.86666666666667%)]\tLoss: 0.3129080832004547\n",
      "Train Epoch: 2 [27840/60000 (46.4%)]\tLoss: 0.02515188790857792\n",
      "Train Epoch: 2 [28160/60000 (46.93333333333333%)]\tLoss: 0.09842130541801453\n",
      "Train Epoch: 2 [28480/60000 (47.46666666666667%)]\tLoss: 0.003113174345344305\n",
      "Train Epoch: 2 [28800/60000 (48.0%)]\tLoss: 0.051167331635951996\n",
      "Train Epoch: 2 [29120/60000 (48.53333333333333%)]\tLoss: 0.06622788310050964\n",
      "Train Epoch: 2 [29440/60000 (49.06666666666667%)]\tLoss: 0.013152056373655796\n",
      "Train Epoch: 2 [29760/60000 (49.6%)]\tLoss: 0.008353665471076965\n",
      "Train Epoch: 2 [30080/60000 (50.13333333333333%)]\tLoss: 0.011553886346518993\n",
      "Train Epoch: 2 [30400/60000 (50.666666666666664%)]\tLoss: 0.03234853595495224\n",
      "Train Epoch: 2 [30720/60000 (51.2%)]\tLoss: 0.026581715792417526\n",
      "Train Epoch: 2 [31040/60000 (51.733333333333334%)]\tLoss: 0.03042273223400116\n",
      "Train Epoch: 2 [31360/60000 (52.266666666666666%)]\tLoss: 0.030837133526802063\n",
      "Train Epoch: 2 [31680/60000 (52.8%)]\tLoss: 0.1038409024477005\n",
      "Train Epoch: 2 [32000/60000 (53.333333333333336%)]\tLoss: 0.1034054383635521\n",
      "Train Epoch: 2 [32320/60000 (53.86666666666667%)]\tLoss: 0.2501593232154846\n",
      "Train Epoch: 2 [32640/60000 (54.4%)]\tLoss: 0.05606964975595474\n",
      "Train Epoch: 2 [32960/60000 (54.93333333333333%)]\tLoss: 0.0010963338427245617\n",
      "Train Epoch: 2 [33280/60000 (55.46666666666667%)]\tLoss: 0.04759734496474266\n",
      "Train Epoch: 2 [33600/60000 (56.0%)]\tLoss: 0.037477243691682816\n",
      "Train Epoch: 2 [33920/60000 (56.53333333333333%)]\tLoss: 0.002306991023942828\n",
      "Train Epoch: 2 [34240/60000 (57.06666666666667%)]\tLoss: 0.0033369821030646563\n",
      "Train Epoch: 2 [34560/60000 (57.6%)]\tLoss: 0.007516460958868265\n",
      "Train Epoch: 2 [34880/60000 (58.13333333333333%)]\tLoss: 0.042150918394327164\n",
      "Train Epoch: 2 [35200/60000 (58.666666666666664%)]\tLoss: 0.03311752900481224\n",
      "Train Epoch: 2 [35520/60000 (59.2%)]\tLoss: 0.009324789978563786\n",
      "Train Epoch: 2 [35840/60000 (59.733333333333334%)]\tLoss: 0.11040341854095459\n",
      "Train Epoch: 2 [36160/60000 (60.266666666666666%)]\tLoss: 0.009579659439623356\n",
      "Train Epoch: 2 [36480/60000 (60.8%)]\tLoss: 0.02621733956038952\n",
      "Train Epoch: 2 [36800/60000 (61.333333333333336%)]\tLoss: 0.0044633480720222\n",
      "Train Epoch: 2 [37120/60000 (61.86666666666667%)]\tLoss: 0.01937832497060299\n",
      "Train Epoch: 2 [37440/60000 (62.4%)]\tLoss: 0.14052650332450867\n",
      "Train Epoch: 2 [37760/60000 (62.93333333333333%)]\tLoss: 0.03404206037521362\n",
      "Train Epoch: 2 [38080/60000 (63.46666666666667%)]\tLoss: 0.001653319108299911\n",
      "Train Epoch: 2 [38400/60000 (64.0%)]\tLoss: 0.10550740361213684\n",
      "Train Epoch: 2 [38720/60000 (64.53333333333333%)]\tLoss: 0.00896824523806572\n",
      "Train Epoch: 2 [39040/60000 (65.06666666666666%)]\tLoss: 0.0010226626181975007\n",
      "Train Epoch: 2 [39360/60000 (65.6%)]\tLoss: 0.15953627228736877\n",
      "Train Epoch: 2 [39680/60000 (66.13333333333334%)]\tLoss: 0.043634843081235886\n",
      "Train Epoch: 2 [40000/60000 (66.66666666666667%)]\tLoss: 0.05202420428395271\n",
      "Train Epoch: 2 [40320/60000 (67.2%)]\tLoss: 0.0005603710887953639\n",
      "Train Epoch: 2 [40640/60000 (67.73333333333333%)]\tLoss: 0.00660527590662241\n",
      "Train Epoch: 2 [40960/60000 (68.26666666666667%)]\tLoss: 0.14307202398777008\n",
      "Train Epoch: 2 [41280/60000 (68.8%)]\tLoss: 0.10223051905632019\n",
      "Train Epoch: 2 [41600/60000 (69.33333333333333%)]\tLoss: 0.18060463666915894\n",
      "Train Epoch: 2 [41920/60000 (69.86666666666666%)]\tLoss: 0.040909841656684875\n",
      "Train Epoch: 2 [42240/60000 (70.4%)]\tLoss: 0.014028969220817089\n",
      "Train Epoch: 2 [42560/60000 (70.93333333333334%)]\tLoss: 0.28989213705062866\n",
      "Train Epoch: 2 [42880/60000 (71.46666666666667%)]\tLoss: 0.027952050790190697\n",
      "Train Epoch: 2 [43200/60000 (72.0%)]\tLoss: 0.10096475481987\n",
      "Train Epoch: 2 [43520/60000 (72.53333333333333%)]\tLoss: 0.06129881367087364\n",
      "Train Epoch: 2 [43840/60000 (73.06666666666666%)]\tLoss: 0.018281307071447372\n",
      "Train Epoch: 2 [44160/60000 (73.6%)]\tLoss: 0.004087933339178562\n",
      "Train Epoch: 2 [44480/60000 (74.13333333333334%)]\tLoss: 0.005083614028990269\n",
      "Train Epoch: 2 [44800/60000 (74.66666666666667%)]\tLoss: 0.017196737229824066\n",
      "Train Epoch: 2 [45120/60000 (75.2%)]\tLoss: 0.07096199691295624\n",
      "Train Epoch: 2 [45440/60000 (75.73333333333333%)]\tLoss: 0.007972178980708122\n",
      "Train Epoch: 2 [45760/60000 (76.26666666666667%)]\tLoss: 0.18085233867168427\n",
      "Train Epoch: 2 [46080/60000 (76.8%)]\tLoss: 0.12765537202358246\n",
      "Train Epoch: 2 [46400/60000 (77.33333333333333%)]\tLoss: 0.0808524340391159\n",
      "Train Epoch: 2 [46720/60000 (77.86666666666666%)]\tLoss: 0.01924094744026661\n",
      "Train Epoch: 2 [47040/60000 (78.4%)]\tLoss: 0.005508835893124342\n",
      "Train Epoch: 2 [47360/60000 (78.93333333333334%)]\tLoss: 0.025392374023795128\n",
      "Train Epoch: 2 [47680/60000 (79.46666666666667%)]\tLoss: 0.04887117072939873\n",
      "Train Epoch: 2 [48000/60000 (80.0%)]\tLoss: 0.03184714540839195\n",
      "Train Epoch: 2 [48320/60000 (80.53333333333333%)]\tLoss: 0.0565330944955349\n",
      "Train Epoch: 2 [48640/60000 (81.06666666666666%)]\tLoss: 0.001243080128915608\n",
      "Train Epoch: 2 [48960/60000 (81.6%)]\tLoss: 0.2748558819293976\n",
      "Train Epoch: 2 [49280/60000 (82.13333333333334%)]\tLoss: 0.011787273921072483\n",
      "Train Epoch: 2 [49600/60000 (82.66666666666667%)]\tLoss: 0.002967419568449259\n",
      "Train Epoch: 2 [49920/60000 (83.2%)]\tLoss: 0.03633645921945572\n",
      "Train Epoch: 2 [50240/60000 (83.73333333333333%)]\tLoss: 0.038791634142398834\n",
      "Train Epoch: 2 [50560/60000 (84.26666666666667%)]\tLoss: 0.06955939531326294\n",
      "Train Epoch: 2 [50880/60000 (84.8%)]\tLoss: 0.0852508619427681\n",
      "Train Epoch: 2 [51200/60000 (85.33333333333333%)]\tLoss: 0.0037900570314377546\n",
      "Train Epoch: 2 [51520/60000 (85.86666666666666%)]\tLoss: 0.05789871886372566\n",
      "Train Epoch: 2 [51840/60000 (86.4%)]\tLoss: 0.03468170762062073\n",
      "Train Epoch: 2 [52160/60000 (86.93333333333334%)]\tLoss: 0.01451683510094881\n",
      "Train Epoch: 2 [52480/60000 (87.46666666666667%)]\tLoss: 0.001044092234224081\n",
      "Train Epoch: 2 [52800/60000 (88.0%)]\tLoss: 0.0804814025759697\n",
      "Train Epoch: 2 [53120/60000 (88.53333333333333%)]\tLoss: 0.015897691249847412\n",
      "Train Epoch: 2 [53440/60000 (89.06666666666666%)]\tLoss: 0.07682745158672333\n",
      "Train Epoch: 2 [53760/60000 (89.6%)]\tLoss: 0.04216321185231209\n",
      "Train Epoch: 2 [54080/60000 (90.13333333333334%)]\tLoss: 0.07154716551303864\n",
      "Train Epoch: 2 [54400/60000 (90.66666666666667%)]\tLoss: 0.005154630169272423\n",
      "Train Epoch: 2 [54720/60000 (91.2%)]\tLoss: 0.08926323056221008\n",
      "Train Epoch: 2 [55040/60000 (91.73333333333333%)]\tLoss: 0.005646144971251488\n",
      "Train Epoch: 2 [55360/60000 (92.26666666666667%)]\tLoss: 0.04617087543010712\n",
      "Train Epoch: 2 [55680/60000 (92.8%)]\tLoss: 0.0015543140470981598\n",
      "Train Epoch: 2 [56000/60000 (93.33333333333333%)]\tLoss: 0.017749890685081482\n",
      "Train Epoch: 2 [56320/60000 (93.86666666666666%)]\tLoss: 0.04549122601747513\n",
      "Train Epoch: 2 [56640/60000 (94.4%)]\tLoss: 0.008445924147963524\n",
      "Train Epoch: 2 [56960/60000 (94.93333333333334%)]\tLoss: 0.026078317314386368\n",
      "Train Epoch: 2 [57280/60000 (95.46666666666667%)]\tLoss: 0.05386701971292496\n",
      "Train Epoch: 2 [57600/60000 (96.0%)]\tLoss: 0.09633468836545944\n",
      "Train Epoch: 2 [57920/60000 (96.53333333333333%)]\tLoss: 0.006688905414193869\n",
      "Train Epoch: 2 [58240/60000 (97.06666666666666%)]\tLoss: 0.02824261039495468\n",
      "Train Epoch: 2 [58560/60000 (97.6%)]\tLoss: 0.0034826858900487423\n",
      "Train Epoch: 2 [58880/60000 (98.13333333333334%)]\tLoss: 0.000322218838846311\n",
      "Train Epoch: 2 [59200/60000 (98.66666666666667%)]\tLoss: 0.00015084340702742338\n",
      "Train Epoch: 2 [59520/60000 (99.2%)]\tLoss: 0.0003183776861988008\n",
      "Train Epoch: 2 [59840/60000 (99.73333333333333%)]\tLoss: 0.0005741085624322295\n",
      "\n",
      "Test set: Avg. loss: 0.0018399072578176856, Accuracy: 9870/10000 (98.69999694824219%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0.0%)]\tLoss: 0.026500793173909187\n",
      "Train Epoch: 3 [320/60000 (0.5333333333333333%)]\tLoss: 0.017404071986675262\n",
      "Train Epoch: 3 [640/60000 (1.0666666666666667%)]\tLoss: 0.005909437779337168\n",
      "Train Epoch: 3 [960/60000 (1.6%)]\tLoss: 0.006100020837038755\n",
      "Train Epoch: 3 [1280/60000 (2.1333333333333333%)]\tLoss: 0.01488630659878254\n",
      "Train Epoch: 3 [1600/60000 (2.6666666666666665%)]\tLoss: 0.17956018447875977\n",
      "Train Epoch: 3 [1920/60000 (3.2%)]\tLoss: 0.03866675868630409\n",
      "Train Epoch: 3 [2240/60000 (3.7333333333333334%)]\tLoss: 0.12650176882743835\n",
      "Train Epoch: 3 [2560/60000 (4.266666666666667%)]\tLoss: 0.02884107455611229\n",
      "Train Epoch: 3 [2880/60000 (4.8%)]\tLoss: 0.12309195101261139\n",
      "Train Epoch: 3 [3200/60000 (5.333333333333333%)]\tLoss: 0.00819902028888464\n",
      "Train Epoch: 3 [3520/60000 (5.866666666666666%)]\tLoss: 0.2408865988254547\n",
      "Train Epoch: 3 [3840/60000 (6.4%)]\tLoss: 0.001418784144334495\n",
      "Train Epoch: 3 [4160/60000 (6.933333333333334%)]\tLoss: 0.006595592014491558\n",
      "Train Epoch: 3 [4480/60000 (7.466666666666667%)]\tLoss: 0.015273144468665123\n",
      "Train Epoch: 3 [4800/60000 (8.0%)]\tLoss: 0.028103895485401154\n",
      "Train Epoch: 3 [5120/60000 (8.533333333333333%)]\tLoss: 0.022445902228355408\n",
      "Train Epoch: 3 [5440/60000 (9.066666666666666%)]\tLoss: 0.03289416432380676\n",
      "Train Epoch: 3 [5760/60000 (9.6%)]\tLoss: 0.020317835733294487\n",
      "Train Epoch: 3 [6080/60000 (10.133333333333333%)]\tLoss: 0.0033724848181009293\n",
      "Train Epoch: 3 [6400/60000 (10.666666666666666%)]\tLoss: 0.07535412907600403\n",
      "Train Epoch: 3 [6720/60000 (11.2%)]\tLoss: 0.007718204520642757\n",
      "Train Epoch: 3 [7040/60000 (11.733333333333333%)]\tLoss: 0.018377134576439857\n",
      "Train Epoch: 3 [7360/60000 (12.266666666666667%)]\tLoss: 0.015359687618911266\n",
      "Train Epoch: 3 [7680/60000 (12.8%)]\tLoss: 0.011936735361814499\n",
      "Train Epoch: 3 [8000/60000 (13.333333333333334%)]\tLoss: 0.01907489448785782\n",
      "Train Epoch: 3 [8320/60000 (13.866666666666667%)]\tLoss: 0.019272534176707268\n",
      "Train Epoch: 3 [8640/60000 (14.4%)]\tLoss: 0.01362181082367897\n",
      "Train Epoch: 3 [8960/60000 (14.933333333333334%)]\tLoss: 0.11001762002706528\n",
      "Train Epoch: 3 [9280/60000 (15.466666666666667%)]\tLoss: 0.0980285257101059\n",
      "Train Epoch: 3 [9600/60000 (16.0%)]\tLoss: 0.008930619806051254\n",
      "Train Epoch: 3 [9920/60000 (16.533333333333335%)]\tLoss: 0.04036344960331917\n",
      "Train Epoch: 3 [10240/60000 (17.066666666666666%)]\tLoss: 0.12911765277385712\n",
      "Train Epoch: 3 [10560/60000 (17.6%)]\tLoss: 0.014908255077898502\n",
      "Train Epoch: 3 [10880/60000 (18.133333333333333%)]\tLoss: 0.0005340578500181437\n",
      "Train Epoch: 3 [11200/60000 (18.666666666666668%)]\tLoss: 0.10460714250802994\n",
      "Train Epoch: 3 [11520/60000 (19.2%)]\tLoss: 0.005365151446312666\n",
      "Train Epoch: 3 [11840/60000 (19.733333333333334%)]\tLoss: 0.06946796923875809\n",
      "Train Epoch: 3 [12160/60000 (20.266666666666666%)]\tLoss: 0.035712338984012604\n",
      "Train Epoch: 3 [12480/60000 (20.8%)]\tLoss: 3.648546771728434e-05\n",
      "Train Epoch: 3 [12800/60000 (21.333333333333332%)]\tLoss: 0.010841157287359238\n",
      "Train Epoch: 3 [13120/60000 (21.866666666666667%)]\tLoss: 0.03529877960681915\n",
      "Train Epoch: 3 [13440/60000 (22.4%)]\tLoss: 0.0034783200826495886\n",
      "Train Epoch: 3 [13760/60000 (22.933333333333334%)]\tLoss: 0.0586068369448185\n",
      "Train Epoch: 3 [14080/60000 (23.466666666666665%)]\tLoss: 0.0006162058562040329\n",
      "Train Epoch: 3 [14400/60000 (24.0%)]\tLoss: 0.010852191597223282\n",
      "Train Epoch: 3 [14720/60000 (24.533333333333335%)]\tLoss: 0.031674642115831375\n",
      "Train Epoch: 3 [15040/60000 (25.066666666666666%)]\tLoss: 0.009224571287631989\n",
      "Train Epoch: 3 [15360/60000 (25.6%)]\tLoss: 0.007946386002004147\n",
      "Train Epoch: 3 [15680/60000 (26.133333333333333%)]\tLoss: 0.0017976254457607865\n",
      "Train Epoch: 3 [16000/60000 (26.666666666666668%)]\tLoss: 0.02005305327475071\n",
      "Train Epoch: 3 [16320/60000 (27.2%)]\tLoss: 0.0009751897305250168\n",
      "Train Epoch: 3 [16640/60000 (27.733333333333334%)]\tLoss: 0.08396074175834656\n",
      "Train Epoch: 3 [16960/60000 (28.266666666666666%)]\tLoss: 0.04653939604759216\n",
      "Train Epoch: 3 [17280/60000 (28.8%)]\tLoss: 0.0005920149269513786\n",
      "Train Epoch: 3 [17600/60000 (29.333333333333332%)]\tLoss: 0.003478342667222023\n",
      "Train Epoch: 3 [17920/60000 (29.866666666666667%)]\tLoss: 0.023112813010811806\n",
      "Train Epoch: 3 [18240/60000 (30.4%)]\tLoss: 0.03325977921485901\n",
      "Train Epoch: 3 [18560/60000 (30.933333333333334%)]\tLoss: 0.001489056390710175\n",
      "Train Epoch: 3 [18880/60000 (31.466666666666665%)]\tLoss: 0.0029842029325664043\n",
      "Train Epoch: 3 [19200/60000 (32.0%)]\tLoss: 0.003319326089695096\n",
      "Train Epoch: 3 [19520/60000 (32.53333333333333%)]\tLoss: 0.01642298325896263\n",
      "Train Epoch: 3 [19840/60000 (33.06666666666667%)]\tLoss: 0.033660829067230225\n",
      "Train Epoch: 3 [20160/60000 (33.6%)]\tLoss: 0.12670624256134033\n",
      "Train Epoch: 3 [20480/60000 (34.13333333333333%)]\tLoss: 0.0007531637093052268\n",
      "Train Epoch: 3 [20800/60000 (34.666666666666664%)]\tLoss: 0.005020535085350275\n",
      "Train Epoch: 3 [21120/60000 (35.2%)]\tLoss: 0.23147621750831604\n",
      "Train Epoch: 3 [21440/60000 (35.733333333333334%)]\tLoss: 0.06782865524291992\n",
      "Train Epoch: 3 [21760/60000 (36.266666666666666%)]\tLoss: 0.03531568497419357\n",
      "Train Epoch: 3 [22080/60000 (36.8%)]\tLoss: 0.0021983592305332422\n",
      "Train Epoch: 3 [22400/60000 (37.333333333333336%)]\tLoss: 0.033090636134147644\n",
      "Train Epoch: 3 [22720/60000 (37.86666666666667%)]\tLoss: 0.02105652540922165\n",
      "Train Epoch: 3 [23040/60000 (38.4%)]\tLoss: 0.002041479339823127\n",
      "Train Epoch: 3 [23360/60000 (38.93333333333333%)]\tLoss: 0.006921183783560991\n",
      "Train Epoch: 3 [23680/60000 (39.46666666666667%)]\tLoss: 0.14443929493427277\n",
      "Train Epoch: 3 [24000/60000 (40.0%)]\tLoss: 0.008587495423853397\n",
      "Train Epoch: 3 [24320/60000 (40.53333333333333%)]\tLoss: 0.005353780463337898\n",
      "Train Epoch: 3 [24640/60000 (41.06666666666667%)]\tLoss: 0.04808242991566658\n",
      "Train Epoch: 3 [24960/60000 (41.6%)]\tLoss: 0.004082403611391783\n",
      "Train Epoch: 3 [25280/60000 (42.13333333333333%)]\tLoss: 0.035200875252485275\n",
      "Train Epoch: 3 [25600/60000 (42.666666666666664%)]\tLoss: 0.004172665532678366\n",
      "Train Epoch: 3 [25920/60000 (43.2%)]\tLoss: 0.026044053956866264\n",
      "Train Epoch: 3 [26240/60000 (43.733333333333334%)]\tLoss: 0.006065117660909891\n",
      "Train Epoch: 3 [26560/60000 (44.266666666666666%)]\tLoss: 0.3867262899875641\n",
      "Train Epoch: 3 [26880/60000 (44.8%)]\tLoss: 0.028841938823461533\n",
      "Train Epoch: 3 [27200/60000 (45.333333333333336%)]\tLoss: 0.0005003911210224032\n",
      "Train Epoch: 3 [27520/60000 (45.86666666666667%)]\tLoss: 0.1128009483218193\n",
      "Train Epoch: 3 [27840/60000 (46.4%)]\tLoss: 0.04329561069607735\n",
      "Train Epoch: 3 [28160/60000 (46.93333333333333%)]\tLoss: 0.05290932208299637\n",
      "Train Epoch: 3 [28480/60000 (47.46666666666667%)]\tLoss: 0.0009070034720934927\n",
      "Train Epoch: 3 [28800/60000 (48.0%)]\tLoss: 0.002129842061549425\n",
      "Train Epoch: 3 [29120/60000 (48.53333333333333%)]\tLoss: 0.0018351739272475243\n",
      "Train Epoch: 3 [29440/60000 (49.06666666666667%)]\tLoss: 0.19782041013240814\n",
      "Train Epoch: 3 [29760/60000 (49.6%)]\tLoss: 0.013594619929790497\n",
      "Train Epoch: 3 [30080/60000 (50.13333333333333%)]\tLoss: 0.007692769169807434\n",
      "Train Epoch: 3 [30400/60000 (50.666666666666664%)]\tLoss: 0.0019133531022816896\n",
      "Train Epoch: 3 [30720/60000 (51.2%)]\tLoss: 0.017620600759983063\n",
      "Train Epoch: 3 [31040/60000 (51.733333333333334%)]\tLoss: 0.019162222743034363\n",
      "Train Epoch: 3 [31360/60000 (52.266666666666666%)]\tLoss: 0.0029103944543749094\n",
      "Train Epoch: 3 [31680/60000 (52.8%)]\tLoss: 0.009210754185914993\n",
      "Train Epoch: 3 [32000/60000 (53.333333333333336%)]\tLoss: 0.04093137010931969\n",
      "Train Epoch: 3 [32320/60000 (53.86666666666667%)]\tLoss: 0.4163859188556671\n",
      "Train Epoch: 3 [32640/60000 (54.4%)]\tLoss: 0.009306544438004494\n",
      "Train Epoch: 3 [32960/60000 (54.93333333333333%)]\tLoss: 0.0005688876262865961\n",
      "Train Epoch: 3 [33280/60000 (55.46666666666667%)]\tLoss: 0.0037958775646984577\n",
      "Train Epoch: 3 [33600/60000 (56.0%)]\tLoss: 0.012588409706950188\n",
      "Train Epoch: 3 [33920/60000 (56.53333333333333%)]\tLoss: 0.0014659501612186432\n",
      "Train Epoch: 3 [34240/60000 (57.06666666666667%)]\tLoss: 0.0018477345583960414\n",
      "Train Epoch: 3 [34560/60000 (57.6%)]\tLoss: 0.009604020975530148\n",
      "Train Epoch: 3 [34880/60000 (58.13333333333333%)]\tLoss: 0.004420653451234102\n",
      "Train Epoch: 3 [35200/60000 (58.666666666666664%)]\tLoss: 0.00983368419110775\n",
      "Train Epoch: 3 [35520/60000 (59.2%)]\tLoss: 0.005323354620486498\n",
      "Train Epoch: 3 [35840/60000 (59.733333333333334%)]\tLoss: 0.03132416307926178\n",
      "Train Epoch: 3 [36160/60000 (60.266666666666666%)]\tLoss: 0.009367810562252998\n",
      "Train Epoch: 3 [36480/60000 (60.8%)]\tLoss: 0.0023449184373021126\n",
      "Train Epoch: 3 [36800/60000 (61.333333333333336%)]\tLoss: 0.11559777706861496\n",
      "Train Epoch: 3 [37120/60000 (61.86666666666667%)]\tLoss: 0.010180843994021416\n",
      "Train Epoch: 3 [37440/60000 (62.4%)]\tLoss: 0.026857800781726837\n",
      "Train Epoch: 3 [37760/60000 (62.93333333333333%)]\tLoss: 0.0026795014273375273\n",
      "Train Epoch: 3 [38080/60000 (63.46666666666667%)]\tLoss: 0.0060607511550188065\n",
      "Train Epoch: 3 [38400/60000 (64.0%)]\tLoss: 0.1688198447227478\n",
      "Train Epoch: 3 [38720/60000 (64.53333333333333%)]\tLoss: 0.001785621396265924\n",
      "Train Epoch: 3 [39040/60000 (65.06666666666666%)]\tLoss: 0.0002441760152578354\n",
      "Train Epoch: 3 [39360/60000 (65.6%)]\tLoss: 0.043886587023735046\n",
      "Train Epoch: 3 [39680/60000 (66.13333333333334%)]\tLoss: 0.026108797639608383\n",
      "Train Epoch: 3 [40000/60000 (66.66666666666667%)]\tLoss: 0.02214406616985798\n",
      "Train Epoch: 3 [40320/60000 (67.2%)]\tLoss: 0.001057003391906619\n",
      "Train Epoch: 3 [40640/60000 (67.73333333333333%)]\tLoss: 0.012538393028080463\n",
      "Train Epoch: 3 [40960/60000 (68.26666666666667%)]\tLoss: 0.07930199801921844\n",
      "Train Epoch: 3 [41280/60000 (68.8%)]\tLoss: 0.1099531278014183\n",
      "Train Epoch: 3 [41600/60000 (69.33333333333333%)]\tLoss: 0.031443770974874496\n",
      "Train Epoch: 3 [41920/60000 (69.86666666666666%)]\tLoss: 0.04624616354703903\n",
      "Train Epoch: 3 [42240/60000 (70.4%)]\tLoss: 0.0016438370803371072\n",
      "Train Epoch: 3 [42560/60000 (70.93333333333334%)]\tLoss: 0.3527587354183197\n",
      "Train Epoch: 3 [42880/60000 (71.46666666666667%)]\tLoss: 0.007872974500060081\n",
      "Train Epoch: 3 [43200/60000 (72.0%)]\tLoss: 0.020502034574747086\n",
      "Train Epoch: 3 [43520/60000 (72.53333333333333%)]\tLoss: 0.017557324841618538\n",
      "Train Epoch: 3 [43840/60000 (73.06666666666666%)]\tLoss: 0.0024268480483442545\n",
      "Train Epoch: 3 [44160/60000 (73.6%)]\tLoss: 0.000677477044519037\n",
      "Train Epoch: 3 [44480/60000 (74.13333333333334%)]\tLoss: 0.056546974927186966\n",
      "Train Epoch: 3 [44800/60000 (74.66666666666667%)]\tLoss: 0.0014490188332274556\n",
      "Train Epoch: 3 [45120/60000 (75.2%)]\tLoss: 0.14210692048072815\n",
      "Train Epoch: 3 [45440/60000 (75.73333333333333%)]\tLoss: 0.0219876766204834\n",
      "Train Epoch: 3 [45760/60000 (76.26666666666667%)]\tLoss: 0.1077929437160492\n",
      "Train Epoch: 3 [46080/60000 (76.8%)]\tLoss: 0.16516275703907013\n",
      "Train Epoch: 3 [46400/60000 (77.33333333333333%)]\tLoss: 0.014740141108632088\n",
      "Train Epoch: 3 [46720/60000 (77.86666666666666%)]\tLoss: 0.09487593173980713\n",
      "Train Epoch: 3 [47040/60000 (78.4%)]\tLoss: 0.0019400244345888495\n",
      "Train Epoch: 3 [47360/60000 (78.93333333333334%)]\tLoss: 0.014226977713406086\n",
      "Train Epoch: 3 [47680/60000 (79.46666666666667%)]\tLoss: 0.019234193488955498\n",
      "Train Epoch: 3 [48000/60000 (80.0%)]\tLoss: 0.039408128708601\n",
      "Train Epoch: 3 [48320/60000 (80.53333333333333%)]\tLoss: 0.013044934719800949\n",
      "Train Epoch: 3 [48640/60000 (81.06666666666666%)]\tLoss: 0.005150187760591507\n",
      "Train Epoch: 3 [48960/60000 (81.6%)]\tLoss: 0.11579674482345581\n",
      "Train Epoch: 3 [49280/60000 (82.13333333333334%)]\tLoss: 0.004969791043549776\n",
      "Train Epoch: 3 [49600/60000 (82.66666666666667%)]\tLoss: 0.0009848156478255987\n",
      "Train Epoch: 3 [49920/60000 (83.2%)]\tLoss: 0.0036304297391325235\n",
      "Train Epoch: 3 [50240/60000 (83.73333333333333%)]\tLoss: 0.03600505366921425\n",
      "Train Epoch: 3 [50560/60000 (84.26666666666667%)]\tLoss: 0.007011455949395895\n",
      "Train Epoch: 3 [50880/60000 (84.8%)]\tLoss: 0.04625511169433594\n",
      "Train Epoch: 3 [51200/60000 (85.33333333333333%)]\tLoss: 0.019810054451227188\n",
      "Train Epoch: 3 [51520/60000 (85.86666666666666%)]\tLoss: 0.03864061459898949\n",
      "Train Epoch: 3 [51840/60000 (86.4%)]\tLoss: 0.005546624306589365\n",
      "Train Epoch: 3 [52160/60000 (86.93333333333334%)]\tLoss: 0.020915482193231583\n",
      "Train Epoch: 3 [52480/60000 (87.46666666666667%)]\tLoss: 0.007572994101792574\n",
      "Train Epoch: 3 [52800/60000 (88.0%)]\tLoss: 0.03971470147371292\n",
      "Train Epoch: 3 [53120/60000 (88.53333333333333%)]\tLoss: 0.011032349430024624\n",
      "Train Epoch: 3 [53440/60000 (89.06666666666666%)]\tLoss: 0.07837480306625366\n",
      "Train Epoch: 3 [53760/60000 (89.6%)]\tLoss: 0.0032740833703428507\n",
      "Train Epoch: 3 [54080/60000 (90.13333333333334%)]\tLoss: 0.10471591353416443\n",
      "Train Epoch: 3 [54400/60000 (90.66666666666667%)]\tLoss: 0.0004968281136825681\n",
      "Train Epoch: 3 [54720/60000 (91.2%)]\tLoss: 0.00515161594375968\n",
      "Train Epoch: 3 [55040/60000 (91.73333333333333%)]\tLoss: 0.0008422706741839647\n",
      "Train Epoch: 3 [55360/60000 (92.26666666666667%)]\tLoss: 0.004755958449095488\n",
      "Train Epoch: 3 [55680/60000 (92.8%)]\tLoss: 0.020871547982096672\n",
      "Train Epoch: 3 [56000/60000 (93.33333333333333%)]\tLoss: 0.10406399518251419\n",
      "Train Epoch: 3 [56320/60000 (93.86666666666666%)]\tLoss: 0.0028845679480582476\n",
      "Train Epoch: 3 [56640/60000 (94.4%)]\tLoss: 0.00688697537407279\n",
      "Train Epoch: 3 [56960/60000 (94.93333333333334%)]\tLoss: 0.23271360993385315\n",
      "Train Epoch: 3 [57280/60000 (95.46666666666667%)]\tLoss: 0.035539377480745316\n",
      "Train Epoch: 3 [57600/60000 (96.0%)]\tLoss: 0.0087414076551795\n",
      "Train Epoch: 3 [57920/60000 (96.53333333333333%)]\tLoss: 0.000374813680537045\n",
      "Train Epoch: 3 [58240/60000 (97.06666666666666%)]\tLoss: 0.003433574689552188\n",
      "Train Epoch: 3 [58560/60000 (97.6%)]\tLoss: 0.0018141231266781688\n",
      "Train Epoch: 3 [58880/60000 (98.13333333333334%)]\tLoss: 7.40851100999862e-05\n",
      "Train Epoch: 3 [59200/60000 (98.66666666666667%)]\tLoss: 0.0002853439946193248\n",
      "Train Epoch: 3 [59520/60000 (99.2%)]\tLoss: 1.6315883840434253e-05\n",
      "Train Epoch: 3 [59840/60000 (99.73333333333333%)]\tLoss: 0.00023076386423781514\n",
      "\n",
      "Test set: Avg. loss: 0.0012050796067342162, Accuracy: 9899/10000 (98.98999786376953%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0.0%)]\tLoss: 0.005525876767933369\n",
      "Train Epoch: 4 [320/60000 (0.5333333333333333%)]\tLoss: 0.03420558571815491\n",
      "Train Epoch: 4 [640/60000 (1.0666666666666667%)]\tLoss: 0.005457642022520304\n",
      "Train Epoch: 4 [960/60000 (1.6%)]\tLoss: 0.007906029000878334\n",
      "Train Epoch: 4 [1280/60000 (2.1333333333333333%)]\tLoss: 0.002268515294417739\n",
      "Train Epoch: 4 [1600/60000 (2.6666666666666665%)]\tLoss: 0.150838702917099\n",
      "Train Epoch: 4 [1920/60000 (3.2%)]\tLoss: 0.2354861944913864\n",
      "Train Epoch: 4 [2240/60000 (3.7333333333333334%)]\tLoss: 0.002298205392435193\n",
      "Train Epoch: 4 [2560/60000 (4.266666666666667%)]\tLoss: 0.005935586988925934\n",
      "Train Epoch: 4 [2880/60000 (4.8%)]\tLoss: 0.18305565416812897\n",
      "Train Epoch: 4 [3200/60000 (5.333333333333333%)]\tLoss: 0.02653716877102852\n",
      "Train Epoch: 4 [3520/60000 (5.866666666666666%)]\tLoss: 0.1641373485326767\n",
      "Train Epoch: 4 [3840/60000 (6.4%)]\tLoss: 0.0018333718180656433\n",
      "Train Epoch: 4 [4160/60000 (6.933333333333334%)]\tLoss: 0.004225450102239847\n",
      "Train Epoch: 4 [4480/60000 (7.466666666666667%)]\tLoss: 0.004793005064129829\n",
      "Train Epoch: 4 [4800/60000 (8.0%)]\tLoss: 0.005523001775145531\n",
      "Train Epoch: 4 [5120/60000 (8.533333333333333%)]\tLoss: 0.0019686545711010695\n",
      "Train Epoch: 4 [5440/60000 (9.066666666666666%)]\tLoss: 0.003644724143669009\n",
      "Train Epoch: 4 [5760/60000 (9.6%)]\tLoss: 0.022189343348145485\n",
      "Train Epoch: 4 [6080/60000 (10.133333333333333%)]\tLoss: 0.005489871371537447\n",
      "Train Epoch: 4 [6400/60000 (10.666666666666666%)]\tLoss: 0.07302232086658478\n",
      "Train Epoch: 4 [6720/60000 (11.2%)]\tLoss: 0.00589462136849761\n",
      "Train Epoch: 4 [7040/60000 (11.733333333333333%)]\tLoss: 0.004567975178360939\n",
      "Train Epoch: 4 [7360/60000 (12.266666666666667%)]\tLoss: 0.01322935614734888\n",
      "Train Epoch: 4 [7680/60000 (12.8%)]\tLoss: 0.006805384997278452\n",
      "Train Epoch: 4 [8000/60000 (13.333333333333334%)]\tLoss: 0.0032275384292006493\n",
      "Train Epoch: 4 [8320/60000 (13.866666666666667%)]\tLoss: 0.12114344537258148\n",
      "Train Epoch: 4 [8640/60000 (14.4%)]\tLoss: 0.08135032653808594\n",
      "Train Epoch: 4 [8960/60000 (14.933333333333334%)]\tLoss: 0.038771819323301315\n",
      "Train Epoch: 4 [9280/60000 (15.466666666666667%)]\tLoss: 0.0066161504946649075\n",
      "Train Epoch: 4 [9600/60000 (16.0%)]\tLoss: 0.00628085620701313\n",
      "Train Epoch: 4 [9920/60000 (16.533333333333335%)]\tLoss: 0.02654031477868557\n",
      "Train Epoch: 4 [10240/60000 (17.066666666666666%)]\tLoss: 0.02368980646133423\n",
      "Train Epoch: 4 [10560/60000 (17.6%)]\tLoss: 9.32013335841475e-06\n",
      "Train Epoch: 4 [10880/60000 (18.133333333333333%)]\tLoss: 0.0004642992280423641\n",
      "Train Epoch: 4 [11200/60000 (18.666666666666668%)]\tLoss: 0.07732027769088745\n",
      "Train Epoch: 4 [11520/60000 (19.2%)]\tLoss: 0.03799981623888016\n",
      "Train Epoch: 4 [11840/60000 (19.733333333333334%)]\tLoss: 0.034464575350284576\n",
      "Train Epoch: 4 [12160/60000 (20.266666666666666%)]\tLoss: 0.008536245673894882\n",
      "Train Epoch: 4 [12480/60000 (20.8%)]\tLoss: 5.9736528783105314e-05\n",
      "Train Epoch: 4 [12800/60000 (21.333333333333332%)]\tLoss: 0.01494210958480835\n",
      "Train Epoch: 4 [13120/60000 (21.866666666666667%)]\tLoss: 0.024718619883060455\n",
      "Train Epoch: 4 [13440/60000 (22.4%)]\tLoss: 0.013720693066716194\n",
      "Train Epoch: 4 [13760/60000 (22.933333333333334%)]\tLoss: 0.0025264224968850613\n",
      "Train Epoch: 4 [14080/60000 (23.466666666666665%)]\tLoss: 0.00011869739682879299\n",
      "Train Epoch: 4 [14400/60000 (24.0%)]\tLoss: 0.0007497420301660895\n",
      "Train Epoch: 4 [14720/60000 (24.533333333333335%)]\tLoss: 0.031128857284784317\n",
      "Train Epoch: 4 [15040/60000 (25.066666666666666%)]\tLoss: 0.09330753237009048\n",
      "Train Epoch: 4 [15360/60000 (25.6%)]\tLoss: 0.0015754938358440995\n",
      "Train Epoch: 4 [15680/60000 (26.133333333333333%)]\tLoss: 0.0006358901737257838\n",
      "Train Epoch: 4 [16000/60000 (26.666666666666668%)]\tLoss: 0.016409261152148247\n",
      "Train Epoch: 4 [16320/60000 (27.2%)]\tLoss: 0.0013132134918123484\n",
      "Train Epoch: 4 [16640/60000 (27.733333333333334%)]\tLoss: 0.15050290524959564\n",
      "Train Epoch: 4 [16960/60000 (28.266666666666666%)]\tLoss: 0.013462107628583908\n",
      "Train Epoch: 4 [17280/60000 (28.8%)]\tLoss: 0.0006080975872464478\n",
      "Train Epoch: 4 [17600/60000 (29.333333333333332%)]\tLoss: 0.0037471121177077293\n",
      "Train Epoch: 4 [17920/60000 (29.866666666666667%)]\tLoss: 0.011263210326433182\n",
      "Train Epoch: 4 [18240/60000 (30.4%)]\tLoss: 0.04085169732570648\n",
      "Train Epoch: 4 [18560/60000 (30.933333333333334%)]\tLoss: 0.026322796940803528\n",
      "Train Epoch: 4 [18880/60000 (31.466666666666665%)]\tLoss: 0.002294772770255804\n",
      "Train Epoch: 4 [19200/60000 (32.0%)]\tLoss: 0.0014412542805075645\n",
      "Train Epoch: 4 [19520/60000 (32.53333333333333%)]\tLoss: 0.006719332188367844\n",
      "Train Epoch: 4 [19840/60000 (33.06666666666667%)]\tLoss: 0.004198706243187189\n",
      "Train Epoch: 4 [20160/60000 (33.6%)]\tLoss: 0.014147903770208359\n",
      "Train Epoch: 4 [20480/60000 (34.13333333333333%)]\tLoss: 0.023572061210870743\n",
      "Train Epoch: 4 [20800/60000 (34.666666666666664%)]\tLoss: 0.04668665677309036\n",
      "Train Epoch: 4 [21120/60000 (35.2%)]\tLoss: 0.061431266367435455\n",
      "Train Epoch: 4 [21440/60000 (35.733333333333334%)]\tLoss: 0.006546135060489178\n",
      "Train Epoch: 4 [21760/60000 (36.266666666666666%)]\tLoss: 0.009783599525690079\n",
      "Train Epoch: 4 [22080/60000 (36.8%)]\tLoss: 0.003161888336762786\n",
      "Train Epoch: 4 [22400/60000 (37.333333333333336%)]\tLoss: 0.0014569265767931938\n",
      "Train Epoch: 4 [22720/60000 (37.86666666666667%)]\tLoss: 0.002838647225871682\n",
      "Train Epoch: 4 [23040/60000 (38.4%)]\tLoss: 0.0002240826142951846\n",
      "Train Epoch: 4 [23360/60000 (38.93333333333333%)]\tLoss: 0.0002699097094591707\n",
      "Train Epoch: 4 [23680/60000 (39.46666666666667%)]\tLoss: 0.00461684912443161\n",
      "Train Epoch: 4 [24000/60000 (40.0%)]\tLoss: 0.01880691573023796\n",
      "Train Epoch: 4 [24320/60000 (40.53333333333333%)]\tLoss: 0.0007167216972447932\n",
      "Train Epoch: 4 [24640/60000 (41.06666666666667%)]\tLoss: 0.09781531244516373\n",
      "Train Epoch: 4 [24960/60000 (41.6%)]\tLoss: 0.00893001351505518\n",
      "Train Epoch: 4 [25280/60000 (42.13333333333333%)]\tLoss: 0.012537344358861446\n",
      "Train Epoch: 4 [25600/60000 (42.666666666666664%)]\tLoss: 0.0001045517492457293\n",
      "Train Epoch: 4 [25920/60000 (43.2%)]\tLoss: 0.008387535810470581\n",
      "Train Epoch: 4 [26240/60000 (43.733333333333334%)]\tLoss: 0.0037885357160121202\n",
      "Train Epoch: 4 [26560/60000 (44.266666666666666%)]\tLoss: 0.3189844787120819\n",
      "Train Epoch: 4 [26880/60000 (44.8%)]\tLoss: 0.015779269859194756\n",
      "Train Epoch: 4 [27200/60000 (45.333333333333336%)]\tLoss: 0.00576590234413743\n",
      "Train Epoch: 4 [27520/60000 (45.86666666666667%)]\tLoss: 0.053904660046100616\n",
      "Train Epoch: 4 [27840/60000 (46.4%)]\tLoss: 0.035435304045677185\n",
      "Train Epoch: 4 [28160/60000 (46.93333333333333%)]\tLoss: 0.0348234549164772\n",
      "Train Epoch: 4 [28480/60000 (47.46666666666667%)]\tLoss: 0.0014320453628897667\n",
      "Train Epoch: 4 [28800/60000 (48.0%)]\tLoss: 9.148339449893683e-05\n",
      "Train Epoch: 4 [29120/60000 (48.53333333333333%)]\tLoss: 0.0019439405295997858\n",
      "Train Epoch: 4 [29440/60000 (49.06666666666667%)]\tLoss: 0.006980405189096928\n",
      "Train Epoch: 4 [29760/60000 (49.6%)]\tLoss: 1.6736132238293067e-05\n",
      "Train Epoch: 4 [30080/60000 (50.13333333333333%)]\tLoss: 0.019527263939380646\n",
      "Train Epoch: 4 [30400/60000 (50.666666666666664%)]\tLoss: 0.003528861328959465\n",
      "Train Epoch: 4 [30720/60000 (51.2%)]\tLoss: 0.001092639286071062\n",
      "Train Epoch: 4 [31040/60000 (51.733333333333334%)]\tLoss: 0.01356208510696888\n",
      "Train Epoch: 4 [31360/60000 (52.266666666666666%)]\tLoss: 0.07968814671039581\n",
      "Train Epoch: 4 [31680/60000 (52.8%)]\tLoss: 0.0027091363444924355\n",
      "Train Epoch: 4 [32000/60000 (53.333333333333336%)]\tLoss: 0.07691596448421478\n",
      "Train Epoch: 4 [32320/60000 (53.86666666666667%)]\tLoss: 0.31798115372657776\n",
      "Train Epoch: 4 [32640/60000 (54.4%)]\tLoss: 0.0007525568944402039\n",
      "Train Epoch: 4 [32960/60000 (54.93333333333333%)]\tLoss: 9.634413436288014e-05\n",
      "Train Epoch: 4 [33280/60000 (55.46666666666667%)]\tLoss: 0.0017011287854984403\n",
      "Train Epoch: 4 [33600/60000 (56.0%)]\tLoss: 0.037891607731580734\n",
      "Train Epoch: 4 [33920/60000 (56.53333333333333%)]\tLoss: 0.00037268726737238467\n",
      "Train Epoch: 4 [34240/60000 (57.06666666666667%)]\tLoss: 0.00033370524761267006\n",
      "Train Epoch: 4 [34560/60000 (57.6%)]\tLoss: 0.002544468967244029\n",
      "Train Epoch: 4 [34880/60000 (58.13333333333333%)]\tLoss: 0.0039033859502524137\n",
      "Train Epoch: 4 [35200/60000 (58.666666666666664%)]\tLoss: 0.010930667631328106\n",
      "Train Epoch: 4 [35520/60000 (59.2%)]\tLoss: 0.011250056326389313\n",
      "Train Epoch: 4 [35840/60000 (59.733333333333334%)]\tLoss: 0.060671400278806686\n",
      "Train Epoch: 4 [36160/60000 (60.266666666666666%)]\tLoss: 0.003593684174120426\n",
      "Train Epoch: 4 [36480/60000 (60.8%)]\tLoss: 0.0007820031605660915\n",
      "Train Epoch: 4 [36800/60000 (61.333333333333336%)]\tLoss: 0.009938959963619709\n",
      "Train Epoch: 4 [37120/60000 (61.86666666666667%)]\tLoss: 0.008626860566437244\n",
      "Train Epoch: 4 [37440/60000 (62.4%)]\tLoss: 0.05213358253240585\n",
      "Train Epoch: 4 [37760/60000 (62.93333333333333%)]\tLoss: 0.00046822853619232774\n",
      "Train Epoch: 4 [38080/60000 (63.46666666666667%)]\tLoss: 0.0003156908496748656\n",
      "Train Epoch: 4 [38400/60000 (64.0%)]\tLoss: 0.06671467423439026\n",
      "Train Epoch: 4 [38720/60000 (64.53333333333333%)]\tLoss: 9.76351075223647e-05\n",
      "Train Epoch: 4 [39040/60000 (65.06666666666666%)]\tLoss: 0.003510683076456189\n",
      "Train Epoch: 4 [39360/60000 (65.6%)]\tLoss: 0.2599773705005646\n",
      "Train Epoch: 4 [39680/60000 (66.13333333333334%)]\tLoss: 0.1191474199295044\n",
      "Train Epoch: 4 [40000/60000 (66.66666666666667%)]\tLoss: 0.1613643318414688\n",
      "Train Epoch: 4 [40320/60000 (67.2%)]\tLoss: 0.002662886632606387\n",
      "Train Epoch: 4 [40640/60000 (67.73333333333333%)]\tLoss: 0.004962016828358173\n",
      "Train Epoch: 4 [40960/60000 (68.26666666666667%)]\tLoss: 0.18015795946121216\n",
      "Train Epoch: 4 [41280/60000 (68.8%)]\tLoss: 0.09465013444423676\n",
      "Train Epoch: 4 [41600/60000 (69.33333333333333%)]\tLoss: 0.0747811570763588\n",
      "Train Epoch: 4 [41920/60000 (69.86666666666666%)]\tLoss: 0.003750235540792346\n",
      "Train Epoch: 4 [42240/60000 (70.4%)]\tLoss: 0.0021012097131460905\n",
      "Train Epoch: 4 [42560/60000 (70.93333333333334%)]\tLoss: 0.18889255821704865\n",
      "Train Epoch: 4 [42880/60000 (71.46666666666667%)]\tLoss: 0.006638598162680864\n",
      "Train Epoch: 4 [43200/60000 (72.0%)]\tLoss: 0.008519027382135391\n",
      "Train Epoch: 4 [43520/60000 (72.53333333333333%)]\tLoss: 0.0031473124399781227\n",
      "Train Epoch: 4 [43840/60000 (73.06666666666666%)]\tLoss: 0.007588726468384266\n",
      "Train Epoch: 4 [44160/60000 (73.6%)]\tLoss: 0.0006217779009602964\n",
      "Train Epoch: 4 [44480/60000 (74.13333333333334%)]\tLoss: 0.043556638062000275\n",
      "Train Epoch: 4 [44800/60000 (74.66666666666667%)]\tLoss: 0.0003372194478288293\n",
      "Train Epoch: 4 [45120/60000 (75.2%)]\tLoss: 0.1599459946155548\n",
      "Train Epoch: 4 [45440/60000 (75.73333333333333%)]\tLoss: 0.007000929210335016\n",
      "Train Epoch: 4 [45760/60000 (76.26666666666667%)]\tLoss: 0.004193402361124754\n",
      "Train Epoch: 4 [46080/60000 (76.8%)]\tLoss: 0.2181272655725479\n",
      "Train Epoch: 4 [46400/60000 (77.33333333333333%)]\tLoss: 0.048858873546123505\n",
      "Train Epoch: 4 [46720/60000 (77.86666666666666%)]\tLoss: 0.03166494891047478\n",
      "Train Epoch: 4 [47040/60000 (78.4%)]\tLoss: 0.00041627485188655555\n",
      "Train Epoch: 4 [47360/60000 (78.93333333333334%)]\tLoss: 0.0006977497832849622\n",
      "Train Epoch: 4 [47680/60000 (79.46666666666667%)]\tLoss: 0.0038026876281946898\n",
      "Train Epoch: 4 [48000/60000 (80.0%)]\tLoss: 0.006339282728731632\n",
      "Train Epoch: 4 [48320/60000 (80.53333333333333%)]\tLoss: 0.0006048217765055597\n",
      "Train Epoch: 4 [48640/60000 (81.06666666666666%)]\tLoss: 0.002950276480987668\n",
      "Train Epoch: 4 [48960/60000 (81.6%)]\tLoss: 0.10724672675132751\n",
      "Train Epoch: 4 [49280/60000 (82.13333333333334%)]\tLoss: 0.0024704397656023502\n",
      "Train Epoch: 4 [49600/60000 (82.66666666666667%)]\tLoss: 0.000556456798221916\n",
      "Train Epoch: 4 [49920/60000 (83.2%)]\tLoss: 0.001202648039907217\n",
      "Train Epoch: 4 [50240/60000 (83.73333333333333%)]\tLoss: 0.01159949041903019\n",
      "Train Epoch: 4 [50560/60000 (84.26666666666667%)]\tLoss: 0.009640829637646675\n",
      "Train Epoch: 4 [50880/60000 (84.8%)]\tLoss: 0.04467204213142395\n",
      "Train Epoch: 4 [51200/60000 (85.33333333333333%)]\tLoss: 0.0026703933253884315\n",
      "Train Epoch: 4 [51520/60000 (85.86666666666666%)]\tLoss: 0.006317322142422199\n",
      "Train Epoch: 4 [51840/60000 (86.4%)]\tLoss: 0.012697605416178703\n",
      "Train Epoch: 4 [52160/60000 (86.93333333333334%)]\tLoss: 0.008684293366968632\n",
      "Train Epoch: 4 [52480/60000 (87.46666666666667%)]\tLoss: 0.00010467222455190495\n",
      "Train Epoch: 4 [52800/60000 (88.0%)]\tLoss: 0.002176129724830389\n",
      "Train Epoch: 4 [53120/60000 (88.53333333333333%)]\tLoss: 0.005201364401727915\n",
      "Train Epoch: 4 [53440/60000 (89.06666666666666%)]\tLoss: 0.008499384857714176\n",
      "Train Epoch: 4 [53760/60000 (89.6%)]\tLoss: 0.005580377299338579\n",
      "Train Epoch: 4 [54080/60000 (90.13333333333334%)]\tLoss: 0.050734177231788635\n",
      "Train Epoch: 4 [54400/60000 (90.66666666666667%)]\tLoss: 0.0017940148245543242\n",
      "Train Epoch: 4 [54720/60000 (91.2%)]\tLoss: 0.006220090668648481\n",
      "Train Epoch: 4 [55040/60000 (91.73333333333333%)]\tLoss: 0.012296494096517563\n",
      "Train Epoch: 4 [55360/60000 (92.26666666666667%)]\tLoss: 6.853562808828428e-05\n",
      "Train Epoch: 4 [55680/60000 (92.8%)]\tLoss: 0.0007254553493112326\n",
      "Train Epoch: 4 [56000/60000 (93.33333333333333%)]\tLoss: 0.05753028765320778\n",
      "Train Epoch: 4 [56320/60000 (93.86666666666666%)]\tLoss: 0.0019855520222336054\n",
      "Train Epoch: 4 [56640/60000 (94.4%)]\tLoss: 0.00036876703961752355\n",
      "Train Epoch: 4 [56960/60000 (94.93333333333334%)]\tLoss: 0.0007906287792138755\n",
      "Train Epoch: 4 [57280/60000 (95.46666666666667%)]\tLoss: 0.0007651435444131494\n",
      "Train Epoch: 4 [57600/60000 (96.0%)]\tLoss: 0.0004933588206768036\n",
      "Train Epoch: 4 [57920/60000 (96.53333333333333%)]\tLoss: 0.00017177461995743215\n",
      "Train Epoch: 4 [58240/60000 (97.06666666666666%)]\tLoss: 0.0011183153837919235\n",
      "Train Epoch: 4 [58560/60000 (97.6%)]\tLoss: 8.686740329721943e-05\n",
      "Train Epoch: 4 [58880/60000 (98.13333333333334%)]\tLoss: 6.750807369826362e-05\n",
      "Train Epoch: 4 [59200/60000 (98.66666666666667%)]\tLoss: 1.4155289136397187e-05\n",
      "Train Epoch: 4 [59520/60000 (99.2%)]\tLoss: 0.0017813773592934012\n",
      "Train Epoch: 4 [59840/60000 (99.73333333333333%)]\tLoss: 0.0005439298693090677\n",
      "\n",
      "Test set: Avg. loss: 0.001132472651079297, Accuracy: 9911/10000 (99.11000061035156%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0.0%)]\tLoss: 0.015349187888205051\n",
      "Train Epoch: 5 [320/60000 (0.5333333333333333%)]\tLoss: 0.004399806261062622\n",
      "Train Epoch: 5 [640/60000 (1.0666666666666667%)]\tLoss: 0.0019919509068131447\n",
      "Train Epoch: 5 [960/60000 (1.6%)]\tLoss: 0.00768470810726285\n",
      "Train Epoch: 5 [1280/60000 (2.1333333333333333%)]\tLoss: 0.004309114534407854\n",
      "Train Epoch: 5 [1600/60000 (2.6666666666666665%)]\tLoss: 0.05201107636094093\n",
      "Train Epoch: 5 [1920/60000 (3.2%)]\tLoss: 0.159262016415596\n",
      "Train Epoch: 5 [2240/60000 (3.7333333333333334%)]\tLoss: 0.005532547831535339\n",
      "Train Epoch: 5 [2560/60000 (4.266666666666667%)]\tLoss: 0.041336897760629654\n",
      "Train Epoch: 5 [2880/60000 (4.8%)]\tLoss: 0.1174059733748436\n",
      "Train Epoch: 5 [3200/60000 (5.333333333333333%)]\tLoss: 0.002650854177772999\n",
      "Train Epoch: 5 [3520/60000 (5.866666666666666%)]\tLoss: 0.0893673226237297\n",
      "Train Epoch: 5 [3840/60000 (6.4%)]\tLoss: 0.00039159285370260477\n",
      "Train Epoch: 5 [4160/60000 (6.933333333333334%)]\tLoss: 0.017219796776771545\n",
      "Train Epoch: 5 [4480/60000 (7.466666666666667%)]\tLoss: 0.0039875563234090805\n",
      "Train Epoch: 5 [4800/60000 (8.0%)]\tLoss: 0.0009328146697953343\n",
      "Train Epoch: 5 [5120/60000 (8.533333333333333%)]\tLoss: 0.0011881886748597026\n",
      "Train Epoch: 5 [5440/60000 (9.066666666666666%)]\tLoss: 0.01789846271276474\n",
      "Train Epoch: 5 [5760/60000 (9.6%)]\tLoss: 0.010784481652081013\n",
      "Train Epoch: 5 [6080/60000 (10.133333333333333%)]\tLoss: 0.004066945053637028\n",
      "Train Epoch: 5 [6400/60000 (10.666666666666666%)]\tLoss: 0.011725434102118015\n",
      "Train Epoch: 5 [6720/60000 (11.2%)]\tLoss: 0.0014752305578440428\n",
      "Train Epoch: 5 [7040/60000 (11.733333333333333%)]\tLoss: 0.0007998670334927738\n",
      "Train Epoch: 5 [7360/60000 (12.266666666666667%)]\tLoss: 0.003774165641516447\n",
      "Train Epoch: 5 [7680/60000 (12.8%)]\tLoss: 0.0020345242228358984\n",
      "Train Epoch: 5 [8000/60000 (13.333333333333334%)]\tLoss: 0.006351191084831953\n",
      "Train Epoch: 5 [8320/60000 (13.866666666666667%)]\tLoss: 0.019461683928966522\n",
      "Train Epoch: 5 [8640/60000 (14.4%)]\tLoss: 0.004900816362351179\n",
      "Train Epoch: 5 [8960/60000 (14.933333333333334%)]\tLoss: 0.0005147351766936481\n",
      "Train Epoch: 5 [9280/60000 (15.466666666666667%)]\tLoss: 0.024085499346256256\n",
      "Train Epoch: 5 [9600/60000 (16.0%)]\tLoss: 0.0006369478069245815\n",
      "Train Epoch: 5 [9920/60000 (16.533333333333335%)]\tLoss: 0.10478311032056808\n",
      "Train Epoch: 5 [10240/60000 (17.066666666666666%)]\tLoss: 0.07873230427503586\n",
      "Train Epoch: 5 [10560/60000 (17.6%)]\tLoss: 0.013876335695385933\n",
      "Train Epoch: 5 [10880/60000 (18.133333333333333%)]\tLoss: 0.00028344447491690516\n",
      "Train Epoch: 5 [11200/60000 (18.666666666666668%)]\tLoss: 0.10871510207653046\n",
      "Train Epoch: 5 [11520/60000 (19.2%)]\tLoss: 0.0005090799531899393\n",
      "Train Epoch: 5 [11840/60000 (19.733333333333334%)]\tLoss: 0.018129445612430573\n",
      "Train Epoch: 5 [12160/60000 (20.266666666666666%)]\tLoss: 0.060542818158864975\n",
      "Train Epoch: 5 [12480/60000 (20.8%)]\tLoss: 0.010848094709217548\n",
      "Train Epoch: 5 [12800/60000 (21.333333333333332%)]\tLoss: 0.033894896507263184\n",
      "Train Epoch: 5 [13120/60000 (21.866666666666667%)]\tLoss: 0.025430748239159584\n",
      "Train Epoch: 5 [13440/60000 (22.4%)]\tLoss: 0.0006540566100738943\n",
      "Train Epoch: 5 [13760/60000 (22.933333333333334%)]\tLoss: 0.0012043141759932041\n",
      "Train Epoch: 5 [14080/60000 (23.466666666666665%)]\tLoss: 6.3141906139208e-06\n",
      "Train Epoch: 5 [14400/60000 (24.0%)]\tLoss: 0.002580660628154874\n",
      "Train Epoch: 5 [14720/60000 (24.533333333333335%)]\tLoss: 0.04879416152834892\n",
      "Train Epoch: 5 [15040/60000 (25.066666666666666%)]\tLoss: 0.0653998851776123\n",
      "Train Epoch: 5 [15360/60000 (25.6%)]\tLoss: 0.0016173492185771465\n",
      "Train Epoch: 5 [15680/60000 (26.133333333333333%)]\tLoss: 8.178898133337498e-05\n",
      "Train Epoch: 5 [16000/60000 (26.666666666666668%)]\tLoss: 0.011698869056999683\n",
      "Train Epoch: 5 [16320/60000 (27.2%)]\tLoss: 0.0012892968952655792\n",
      "Train Epoch: 5 [16640/60000 (27.733333333333334%)]\tLoss: 0.050321053713560104\n",
      "Train Epoch: 5 [16960/60000 (28.266666666666666%)]\tLoss: 0.009798687882721424\n",
      "Train Epoch: 5 [17280/60000 (28.8%)]\tLoss: 0.004397714510560036\n",
      "Train Epoch: 5 [17600/60000 (29.333333333333332%)]\tLoss: 0.0008476800285279751\n",
      "Train Epoch: 5 [17920/60000 (29.866666666666667%)]\tLoss: 0.0028431068640202284\n",
      "Train Epoch: 5 [18240/60000 (30.4%)]\tLoss: 0.0019179768860340118\n",
      "Train Epoch: 5 [18560/60000 (30.933333333333334%)]\tLoss: 0.0018031547078862786\n",
      "Train Epoch: 5 [18880/60000 (31.466666666666665%)]\tLoss: 0.0001056285691447556\n",
      "Train Epoch: 5 [19200/60000 (32.0%)]\tLoss: 0.00044321746099740267\n",
      "Train Epoch: 5 [19520/60000 (32.53333333333333%)]\tLoss: 0.001158047583885491\n",
      "Train Epoch: 5 [19840/60000 (33.06666666666667%)]\tLoss: 0.007116822991520166\n",
      "Train Epoch: 5 [20160/60000 (33.6%)]\tLoss: 0.014987397938966751\n",
      "Train Epoch: 5 [20480/60000 (34.13333333333333%)]\tLoss: 4.402417107485235e-05\n",
      "Train Epoch: 5 [20800/60000 (34.666666666666664%)]\tLoss: 0.0011495798826217651\n",
      "Train Epoch: 5 [21120/60000 (35.2%)]\tLoss: 0.1991606205701828\n",
      "Train Epoch: 5 [21440/60000 (35.733333333333334%)]\tLoss: 0.012081250548362732\n",
      "Train Epoch: 5 [21760/60000 (36.266666666666666%)]\tLoss: 0.1159135103225708\n",
      "Train Epoch: 5 [22080/60000 (36.8%)]\tLoss: 0.0013635990908369422\n",
      "Train Epoch: 5 [22400/60000 (37.333333333333336%)]\tLoss: 0.1357862651348114\n",
      "Train Epoch: 5 [22720/60000 (37.86666666666667%)]\tLoss: 0.0006196422036737204\n",
      "Train Epoch: 5 [23040/60000 (38.4%)]\tLoss: 0.04816378280520439\n",
      "Train Epoch: 5 [23360/60000 (38.93333333333333%)]\tLoss: 0.003093524370342493\n",
      "Train Epoch: 5 [23680/60000 (39.46666666666667%)]\tLoss: 0.06373269110918045\n",
      "Train Epoch: 5 [24000/60000 (40.0%)]\tLoss: 0.004599851090461016\n",
      "Train Epoch: 5 [24320/60000 (40.53333333333333%)]\tLoss: 0.0001125477283494547\n",
      "Train Epoch: 5 [24640/60000 (41.06666666666667%)]\tLoss: 0.0009488121140748262\n",
      "Train Epoch: 5 [24960/60000 (41.6%)]\tLoss: 0.0012992884730920196\n",
      "Train Epoch: 5 [25280/60000 (42.13333333333333%)]\tLoss: 0.0075686015188694\n",
      "Train Epoch: 5 [25600/60000 (42.666666666666664%)]\tLoss: 0.0001489289861638099\n",
      "Train Epoch: 5 [25920/60000 (43.2%)]\tLoss: 0.04865829646587372\n",
      "Train Epoch: 5 [26240/60000 (43.733333333333334%)]\tLoss: 0.0003046358469873667\n",
      "Train Epoch: 5 [26560/60000 (44.266666666666666%)]\tLoss: 0.3764030337333679\n",
      "Train Epoch: 5 [26880/60000 (44.8%)]\tLoss: 0.001529210014268756\n",
      "Train Epoch: 5 [27200/60000 (45.333333333333336%)]\tLoss: 0.0005906174192205071\n",
      "Train Epoch: 5 [27520/60000 (45.86666666666667%)]\tLoss: 0.09098098427057266\n",
      "Train Epoch: 5 [27840/60000 (46.4%)]\tLoss: 0.023637741804122925\n",
      "Train Epoch: 5 [28160/60000 (46.93333333333333%)]\tLoss: 0.02701028436422348\n",
      "Train Epoch: 5 [28480/60000 (47.46666666666667%)]\tLoss: 0.0005592374363914132\n",
      "Train Epoch: 5 [28800/60000 (48.0%)]\tLoss: 0.0013736530672758818\n",
      "Train Epoch: 5 [29120/60000 (48.53333333333333%)]\tLoss: 0.0035522643011063337\n",
      "Train Epoch: 5 [29440/60000 (49.06666666666667%)]\tLoss: 0.010186906903982162\n",
      "Train Epoch: 5 [29760/60000 (49.6%)]\tLoss: 0.008782424032688141\n",
      "Train Epoch: 5 [30080/60000 (50.13333333333333%)]\tLoss: 0.00027374018100090325\n",
      "Train Epoch: 5 [30400/60000 (50.666666666666664%)]\tLoss: 0.0006655834731645882\n",
      "Train Epoch: 5 [30720/60000 (51.2%)]\tLoss: 0.0003127955715171993\n",
      "Train Epoch: 5 [31040/60000 (51.733333333333334%)]\tLoss: 0.0066307117231190205\n",
      "Train Epoch: 5 [31360/60000 (52.266666666666666%)]\tLoss: 0.00807166751474142\n",
      "Train Epoch: 5 [31680/60000 (52.8%)]\tLoss: 0.15537229180335999\n",
      "Train Epoch: 5 [32000/60000 (53.333333333333336%)]\tLoss: 0.014271209016442299\n",
      "Train Epoch: 5 [32320/60000 (53.86666666666667%)]\tLoss: 0.2619208097457886\n",
      "Train Epoch: 5 [32640/60000 (54.4%)]\tLoss: 0.001797171775251627\n",
      "Train Epoch: 5 [32960/60000 (54.93333333333333%)]\tLoss: 4.112111491849646e-05\n",
      "Train Epoch: 5 [33280/60000 (55.46666666666667%)]\tLoss: 0.008552897721529007\n",
      "Train Epoch: 5 [33600/60000 (56.0%)]\tLoss: 0.005379266571253538\n",
      "Train Epoch: 5 [33920/60000 (56.53333333333333%)]\tLoss: 0.010737236589193344\n",
      "Train Epoch: 5 [34240/60000 (57.06666666666667%)]\tLoss: 0.0001918723137350753\n",
      "Train Epoch: 5 [34560/60000 (57.6%)]\tLoss: 0.0034153852611780167\n",
      "Train Epoch: 5 [34880/60000 (58.13333333333333%)]\tLoss: 0.006957929581403732\n",
      "Train Epoch: 5 [35200/60000 (58.666666666666664%)]\tLoss: 0.00042688025860115886\n",
      "Train Epoch: 5 [35520/60000 (59.2%)]\tLoss: 0.003227864857763052\n",
      "Train Epoch: 5 [35840/60000 (59.733333333333334%)]\tLoss: 0.0402747318148613\n",
      "Train Epoch: 5 [36160/60000 (60.266666666666666%)]\tLoss: 0.006547271739691496\n",
      "Train Epoch: 5 [36480/60000 (60.8%)]\tLoss: 0.0003126704250462353\n",
      "Train Epoch: 5 [36800/60000 (61.333333333333336%)]\tLoss: 0.12312206625938416\n",
      "Train Epoch: 5 [37120/60000 (61.86666666666667%)]\tLoss: 0.003358917310833931\n",
      "Train Epoch: 5 [37440/60000 (62.4%)]\tLoss: 0.09946388751268387\n",
      "Train Epoch: 5 [37760/60000 (62.93333333333333%)]\tLoss: 0.0003549041866790503\n",
      "Train Epoch: 5 [38080/60000 (63.46666666666667%)]\tLoss: 9.019790741149336e-05\n",
      "Train Epoch: 5 [38400/60000 (64.0%)]\tLoss: 0.032296355813741684\n",
      "Train Epoch: 5 [38720/60000 (64.53333333333333%)]\tLoss: 9.609455446479842e-05\n",
      "Train Epoch: 5 [39040/60000 (65.06666666666666%)]\tLoss: 0.0003609415143728256\n",
      "Train Epoch: 5 [39360/60000 (65.6%)]\tLoss: 0.04160469025373459\n",
      "Train Epoch: 5 [39680/60000 (66.13333333333334%)]\tLoss: 0.033909186720848083\n",
      "Train Epoch: 5 [40000/60000 (66.66666666666667%)]\tLoss: 0.011533169075846672\n",
      "Train Epoch: 5 [40320/60000 (67.2%)]\tLoss: 0.00015637613250873983\n",
      "Train Epoch: 5 [40640/60000 (67.73333333333333%)]\tLoss: 0.004240443464368582\n",
      "Train Epoch: 5 [40960/60000 (68.26666666666667%)]\tLoss: 0.3066875636577606\n",
      "Train Epoch: 5 [41280/60000 (68.8%)]\tLoss: 0.04306801036000252\n",
      "Train Epoch: 5 [41600/60000 (69.33333333333333%)]\tLoss: 0.007172612007707357\n",
      "Train Epoch: 5 [41920/60000 (69.86666666666666%)]\tLoss: 0.033293966203927994\n",
      "Train Epoch: 5 [42240/60000 (70.4%)]\tLoss: 0.0006100930040702224\n",
      "Train Epoch: 5 [42560/60000 (70.93333333333334%)]\tLoss: 0.07807387411594391\n",
      "Train Epoch: 5 [42880/60000 (71.46666666666667%)]\tLoss: 0.010030394420027733\n",
      "Train Epoch: 5 [43200/60000 (72.0%)]\tLoss: 0.0011903854319825768\n",
      "Train Epoch: 5 [43520/60000 (72.53333333333333%)]\tLoss: 0.004152956884354353\n",
      "Train Epoch: 5 [43840/60000 (73.06666666666666%)]\tLoss: 0.00526779517531395\n",
      "Train Epoch: 5 [44160/60000 (73.6%)]\tLoss: 0.013107014819979668\n",
      "Train Epoch: 5 [44480/60000 (74.13333333333334%)]\tLoss: 0.04177919775247574\n",
      "Train Epoch: 5 [44800/60000 (74.66666666666667%)]\tLoss: 0.0007168205920606852\n",
      "Train Epoch: 5 [45120/60000 (75.2%)]\tLoss: 0.07674366235733032\n",
      "Train Epoch: 5 [45440/60000 (75.73333333333333%)]\tLoss: 0.003285561688244343\n",
      "Train Epoch: 5 [45760/60000 (76.26666666666667%)]\tLoss: 0.03144153952598572\n",
      "Train Epoch: 5 [46080/60000 (76.8%)]\tLoss: 0.06442931294441223\n",
      "Train Epoch: 5 [46400/60000 (77.33333333333333%)]\tLoss: 0.015337102115154266\n",
      "Train Epoch: 5 [46720/60000 (77.86666666666666%)]\tLoss: 0.026148822158575058\n",
      "Train Epoch: 5 [47040/60000 (78.4%)]\tLoss: 0.0069253030233085155\n",
      "Train Epoch: 5 [47360/60000 (78.93333333333334%)]\tLoss: 0.00980578362941742\n",
      "Train Epoch: 5 [47680/60000 (79.46666666666667%)]\tLoss: 0.0007533002062700689\n",
      "Train Epoch: 5 [48000/60000 (80.0%)]\tLoss: 0.12362848967313766\n",
      "Train Epoch: 5 [48320/60000 (80.53333333333333%)]\tLoss: 0.0006897313869558275\n",
      "Train Epoch: 5 [48640/60000 (81.06666666666666%)]\tLoss: 0.000629571033641696\n",
      "Train Epoch: 5 [48960/60000 (81.6%)]\tLoss: 0.06182141229510307\n",
      "Train Epoch: 5 [49280/60000 (82.13333333333334%)]\tLoss: 0.0010657424572855234\n",
      "Train Epoch: 5 [49600/60000 (82.66666666666667%)]\tLoss: 0.00241162464953959\n",
      "Train Epoch: 5 [49920/60000 (83.2%)]\tLoss: 0.04068395867943764\n",
      "Train Epoch: 5 [50240/60000 (83.73333333333333%)]\tLoss: 0.0022917650640010834\n",
      "Train Epoch: 5 [50560/60000 (84.26666666666667%)]\tLoss: 0.0064237844198942184\n",
      "Train Epoch: 5 [50880/60000 (84.8%)]\tLoss: 0.045882195234298706\n",
      "Train Epoch: 5 [51200/60000 (85.33333333333333%)]\tLoss: 0.0034386725164949894\n",
      "Train Epoch: 5 [51520/60000 (85.86666666666666%)]\tLoss: 0.008008748292922974\n",
      "Train Epoch: 5 [51840/60000 (86.4%)]\tLoss: 0.0024563937913626432\n",
      "Train Epoch: 5 [52160/60000 (86.93333333333334%)]\tLoss: 0.065808966755867\n",
      "Train Epoch: 5 [52480/60000 (87.46666666666667%)]\tLoss: 0.0006330247269943357\n",
      "Train Epoch: 5 [52800/60000 (88.0%)]\tLoss: 0.06121644750237465\n",
      "Train Epoch: 5 [53120/60000 (88.53333333333333%)]\tLoss: 0.003559727221727371\n",
      "Train Epoch: 5 [53440/60000 (89.06666666666666%)]\tLoss: 0.013775316998362541\n",
      "Train Epoch: 5 [53760/60000 (89.6%)]\tLoss: 0.0012404723092913628\n",
      "Train Epoch: 5 [54080/60000 (90.13333333333334%)]\tLoss: 0.012013474479317665\n",
      "Train Epoch: 5 [54400/60000 (90.66666666666667%)]\tLoss: 0.0017088858876377344\n",
      "Train Epoch: 5 [54720/60000 (91.2%)]\tLoss: 0.028918229043483734\n",
      "Train Epoch: 5 [55040/60000 (91.73333333333333%)]\tLoss: 0.0026187135372310877\n",
      "Train Epoch: 5 [55360/60000 (92.26666666666667%)]\tLoss: 0.0024418120738118887\n",
      "Train Epoch: 5 [55680/60000 (92.8%)]\tLoss: 0.0002867850416805595\n",
      "Train Epoch: 5 [56000/60000 (93.33333333333333%)]\tLoss: 0.009715857915580273\n",
      "Train Epoch: 5 [56320/60000 (93.86666666666666%)]\tLoss: 0.001958361128345132\n",
      "Train Epoch: 5 [56640/60000 (94.4%)]\tLoss: 0.0001251656940439716\n",
      "Train Epoch: 5 [56960/60000 (94.93333333333334%)]\tLoss: 0.00032774830469861627\n",
      "Train Epoch: 5 [57280/60000 (95.46666666666667%)]\tLoss: 0.012974771670997143\n",
      "Train Epoch: 5 [57600/60000 (96.0%)]\tLoss: 0.020315857604146004\n",
      "Train Epoch: 5 [57920/60000 (96.53333333333333%)]\tLoss: 0.00024968848447315395\n",
      "Train Epoch: 5 [58240/60000 (97.06666666666666%)]\tLoss: 0.0009160087793134153\n",
      "Train Epoch: 5 [58560/60000 (97.6%)]\tLoss: 5.3699230193160474e-05\n",
      "Train Epoch: 5 [58880/60000 (98.13333333333334%)]\tLoss: 1.3249197763798293e-05\n",
      "Train Epoch: 5 [59200/60000 (98.66666666666667%)]\tLoss: 8.344049092556816e-06\n",
      "Train Epoch: 5 [59520/60000 (99.2%)]\tLoss: 0.00013219533138908446\n",
      "Train Epoch: 5 [59840/60000 (99.73333333333333%)]\tLoss: 8.632071694592014e-05\n",
      "\n",
      "Test set: Avg. loss: 0.0010118106147274375, Accuracy: 9918/10000 (99.18000030517578%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(mnist_trainset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = DataLoader(mnist_testset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "epoch = 0\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "vgg16.eval()\n",
    "correct = 0\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "  for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = vgg16(data)\n",
    "    test_loss += loss(output, target)\n",
    "    pred = output.data.max(1, keepdim = True)[1]\n",
    "    correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(mnist_testset)\n",
    "test_losses.append(test_loss.item())\n",
    "print(f'\\nTest set: Avg. loss: {test_loss}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset)}%)\\n')\n",
    "\n",
    "while epoch < max_epochs:\n",
    "  epoch += 1\n",
    "  vgg16.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = vgg16(data)\n",
    "    train_loss = loss(output, target)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader)}%)]\\tLoss: {train_loss.item()}')\n",
    "      train_losses.append(train_loss.item())\n",
    "      torch.save(vgg16.state_dict(), './results/vgg16.pth')\n",
    "      torch.save(optimizer.state_dict(), './results/optimizer.pth')\n",
    "      \n",
    "  vgg16.eval()\n",
    "  correct = 0\n",
    "  test_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data = data.to(device)\n",
    "      target = target.to(device)\n",
    "      output = vgg16(data)\n",
    "      test_loss += loss(output, target)\n",
    "      pred = output.data.max(1, keepdim = True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(mnist_testset)\n",
    "  test_losses.append(test_loss.item())\n",
    "  print(f'\\nTest set: Avg. loss: {test_loss}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset)}%)\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec47d1-91c9-4ec3-990f-1ae0957f2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c57d86-1094-4433-ac69-833064c3be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_testset, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388969f-c822-4187-8712-ade766c224a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99998446-7187-4da5-ac91-cd6d7258fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb146d-8e2b-43c8-91f4-c9c7878fdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404c551-615e-437f-bb82-8e054a487918",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0ad90-a38b-4baa-a8d5-07f463d511eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vgg16(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99b45f-e24b-498d-8a8d-0693b560fcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cf33b-d71c-487d-b3b8-54aaeffb2a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
